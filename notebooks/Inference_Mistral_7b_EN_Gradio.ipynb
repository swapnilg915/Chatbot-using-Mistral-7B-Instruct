{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a6e7f9b27d484b33bbd1eef006f742c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5446b050a3704b37964fb2017c62a7e4",
              "IPY_MODEL_40663ebc5ba74033a5ae3d9618a66660",
              "IPY_MODEL_31c21b28b91a4a88ac9b541ede5b3e7b",
              "IPY_MODEL_b141483c8ac844b7a641c8ee81732838"
            ],
            "layout": "IPY_MODEL_d3558d740c1c40e4b5cd309d514568e4"
          }
        },
        "611d89682c12435586d2224bae5ff2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97264df9f41c4690bfcbf295da3271e0",
            "placeholder": "​",
            "style": "IPY_MODEL_6844f10ef3d8402394b431363a65e22f",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "fad6c88af2a24990a625f8ded1f158ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_0e86ca460bc2418faa3f0fff5deab69a",
            "placeholder": "​",
            "style": "IPY_MODEL_fe56d5f118a8495f99e27f6c911d42ee",
            "value": ""
          }
        },
        "7571e536efe24ed4bc6fc97051114102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_e41010bcdff84a3d86b509791efead36",
            "style": "IPY_MODEL_ec329ba4a6c94b0aa8fe8a9aa8d1e34a",
            "value": true
          }
        },
        "938c70cb06be4a12b72789ac1350e6bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_5766063371924ea0a1d070f788c1196f",
            "style": "IPY_MODEL_98f966abd7404997b81abe778e3df69c",
            "tooltip": ""
          }
        },
        "1b0a1bcc0b9f470ebfa39046eef9a34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4360a0f03ec2483e9a81001f69350644",
            "placeholder": "​",
            "style": "IPY_MODEL_f237f7264472450099d2e57c872dee24",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "d3558d740c1c40e4b5cd309d514568e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "97264df9f41c4690bfcbf295da3271e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6844f10ef3d8402394b431363a65e22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e86ca460bc2418faa3f0fff5deab69a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe56d5f118a8495f99e27f6c911d42ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e41010bcdff84a3d86b509791efead36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec329ba4a6c94b0aa8fe8a9aa8d1e34a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5766063371924ea0a1d070f788c1196f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f966abd7404997b81abe778e3df69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "4360a0f03ec2483e9a81001f69350644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f237f7264472450099d2e57c872dee24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cf5b07c4a0e4a11924fd2daa3bce263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af9055ad48d042c4b4b6f1a6ce794f09",
            "placeholder": "​",
            "style": "IPY_MODEL_e985013f3841441e83b802c3b8050f87",
            "value": "Connecting..."
          }
        },
        "af9055ad48d042c4b4b6f1a6ce794f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e985013f3841441e83b802c3b8050f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5446b050a3704b37964fb2017c62a7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_528015b22f2f430d9ba58d631c81a691",
            "placeholder": "​",
            "style": "IPY_MODEL_b86bd2cf927d4379bb30d913596885dc",
            "value": "Token is valid (permission: write)."
          }
        },
        "40663ebc5ba74033a5ae3d9618a66660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b94a46f285b4189b8c8fd7703a3b56b",
            "placeholder": "​",
            "style": "IPY_MODEL_7c2f51ced8d4473ab9b028895aaf4942",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "31c21b28b91a4a88ac9b541ede5b3e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc1c574dad04bf0b6765e845807370e",
            "placeholder": "​",
            "style": "IPY_MODEL_675d0da1c68e44189f47961ea942ac07",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "b141483c8ac844b7a641c8ee81732838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a6c368e52b0455a976dfbc1199d1543",
            "placeholder": "​",
            "style": "IPY_MODEL_7b78c4f6942a4a18a82da6cd113fbafa",
            "value": "Login successful"
          }
        },
        "528015b22f2f430d9ba58d631c81a691": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b86bd2cf927d4379bb30d913596885dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b94a46f285b4189b8c8fd7703a3b56b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c2f51ced8d4473ab9b028895aaf4942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdc1c574dad04bf0b6765e845807370e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "675d0da1c68e44189f47961ea942ac07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a6c368e52b0455a976dfbc1199d1543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b78c4f6942a4a18a82da6cd113fbafa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4655579000e849c2a7a283f453a812ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36fa4d3d148d43cfa2190879e093e9d8",
              "IPY_MODEL_058c4e66ea924115b144400e9ae09528",
              "IPY_MODEL_2d820267e6454430af2847b4b1d6d043"
            ],
            "layout": "IPY_MODEL_52396ace5a754b75ab4c26b8c6c27353"
          }
        },
        "36fa4d3d148d43cfa2190879e093e9d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7244221839445f1bb04d656f56f5642",
            "placeholder": "​",
            "style": "IPY_MODEL_9852d295b5e54522b08579df26136af7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "058c4e66ea924115b144400e9ae09528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9766b980e64d443882cd4dad681fd414",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17314a3cfb744a158ab4f39e17c6f506",
            "value": 8
          }
        },
        "2d820267e6454430af2847b4b1d6d043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebcc3601756d4529a96103f8a4c14987",
            "placeholder": "​",
            "style": "IPY_MODEL_47f57d293cae4cc5909a97fba7bb73c1",
            "value": " 8/8 [00:11&lt;00:00,  1.29s/it]"
          }
        },
        "52396ace5a754b75ab4c26b8c6c27353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7244221839445f1bb04d656f56f5642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9852d295b5e54522b08579df26136af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9766b980e64d443882cd4dad681fd414": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17314a3cfb744a158ab4f39e17c6f506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebcc3601756d4529a96103f8a4c14987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47f57d293cae4cc5909a97fba7bb73c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b82782a1c214068ad05a22eb5391079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69bcbf2fafb74c41940e7e1c63c35abd",
              "IPY_MODEL_e854b7fab8124654913557b521f772fc",
              "IPY_MODEL_e8299be6f35e4f0a86b2ba8b8c2ef71b"
            ],
            "layout": "IPY_MODEL_4e2da159a6004203a79935db7aef0ce9"
          }
        },
        "69bcbf2fafb74c41940e7e1c63c35abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc802b45dc4046c6a54e0835b9bc7584",
            "placeholder": "​",
            "style": "IPY_MODEL_740e9bbbfcb44f07beb4b54d64a00b46",
            "value": "adapter_config.json: 100%"
          }
        },
        "e854b7fab8124654913557b521f772fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c36db8475a43420c984ec4b6943cc75b",
            "max": 599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83ec6bd5fa4c474ea19305757ea435fd",
            "value": 599
          }
        },
        "e8299be6f35e4f0a86b2ba8b8c2ef71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_023721cb450f4b539674b4e6d268dd8a",
            "placeholder": "​",
            "style": "IPY_MODEL_db1ec10d7ff64aadac4d673f177aa818",
            "value": " 599/599 [00:00&lt;00:00, 50.8kB/s]"
          }
        },
        "4e2da159a6004203a79935db7aef0ce9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc802b45dc4046c6a54e0835b9bc7584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "740e9bbbfcb44f07beb4b54d64a00b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c36db8475a43420c984ec4b6943cc75b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ec6bd5fa4c474ea19305757ea435fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "023721cb450f4b539674b4e6d268dd8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db1ec10d7ff64aadac4d673f177aa818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29009715d9814b10b349dafed7d79c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ec303570a5b476fab5653541c26b206",
              "IPY_MODEL_6da50803adb14f89b739f977f1531c32",
              "IPY_MODEL_9c218b8fc7e34e8bab2d89a22da74235"
            ],
            "layout": "IPY_MODEL_d7fb6a2058bd4fbab636f3c363217241"
          }
        },
        "7ec303570a5b476fab5653541c26b206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4204685db1104934ac78700244e80895",
            "placeholder": "​",
            "style": "IPY_MODEL_6fb90a8159b844a2a5f1e82c863943f1",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "6da50803adb14f89b739f977f1531c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bb9d76e78e5491bba59e028af04ba07",
            "max": 27280152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76cfdaee54274f5296f30497c226db8a",
            "value": 27280152
          }
        },
        "9c218b8fc7e34e8bab2d89a22da74235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bef62e595d24899bc4476b2fe77fa1a",
            "placeholder": "​",
            "style": "IPY_MODEL_99ec2d0024a34e9c82d6ed8a0c3a414c",
            "value": " 27.3M/27.3M [00:02&lt;00:00, 12.5MB/s]"
          }
        },
        "d7fb6a2058bd4fbab636f3c363217241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4204685db1104934ac78700244e80895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb90a8159b844a2a5f1e82c863943f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bb9d76e78e5491bba59e028af04ba07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76cfdaee54274f5296f30497c226db8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bef62e595d24899bc4476b2fe77fa1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99ec2d0024a34e9c82d6ed8a0c3a414c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning Mistral 7b with AutoTrain"
      ],
      "metadata": {
        "id": "7oRhTab-3Isg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup Runtime\n",
        "For fine-tuning Llama, a GPU instance is essential. Follow the directions below:\n",
        "\n",
        "- Go to `Runtime` (located in the top menu bar).\n",
        "- Select `Change Runtime Type`.\n",
        "- Choose `T4 GPU` (or a comparable option)."
      ],
      "metadata": {
        "id": "yhDioAdc3ML5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Setup Environment"
      ],
      "metadata": {
        "id": "IJZt3QI73kWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas autotrain-advanced -q"
      ],
      "metadata": {
        "id": "UgvqeBz_3XvO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwStofw4257S",
        "outputId": "9297a9d1-90cd-454f-b6c1-b8d8725c2e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Installing latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest PyTorch\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest PyTorch\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!autotrain setup --update-torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Connect to HuggingFace for Model Upload\n",
        "\n",
        "### Logging to Hugging Face\n",
        "To make sure the model can be uploaded to be used for Inference, it's necessary to log in to the Hugging Face hub.\n",
        "\n",
        "### Getting a Hugging Face token\n",
        "Steps:\n",
        "\n",
        "1. Navigate to this URL: https://huggingface.co/settings/tokens\n",
        "2. Create a write `token` and copy it to your clipboard\n",
        "3. Run the code below and enter your `token`"
      ],
      "metadata": {
        "id": "H-zXccJMZEx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "a6e7f9b27d484b33bbd1eef006f742c2",
            "611d89682c12435586d2224bae5ff2df",
            "fad6c88af2a24990a625f8ded1f158ba",
            "7571e536efe24ed4bc6fc97051114102",
            "938c70cb06be4a12b72789ac1350e6bd",
            "1b0a1bcc0b9f470ebfa39046eef9a34d",
            "d3558d740c1c40e4b5cd309d514568e4",
            "97264df9f41c4690bfcbf295da3271e0",
            "6844f10ef3d8402394b431363a65e22f",
            "0e86ca460bc2418faa3f0fff5deab69a",
            "fe56d5f118a8495f99e27f6c911d42ee",
            "e41010bcdff84a3d86b509791efead36",
            "ec329ba4a6c94b0aa8fe8a9aa8d1e34a",
            "5766063371924ea0a1d070f788c1196f",
            "98f966abd7404997b81abe778e3df69c",
            "4360a0f03ec2483e9a81001f69350644",
            "f237f7264472450099d2e57c872dee24",
            "3cf5b07c4a0e4a11924fd2daa3bce263",
            "af9055ad48d042c4b4b6f1a6ce794f09",
            "e985013f3841441e83b802c3b8050f87",
            "5446b050a3704b37964fb2017c62a7e4",
            "40663ebc5ba74033a5ae3d9618a66660",
            "31c21b28b91a4a88ac9b541ede5b3e7b",
            "b141483c8ac844b7a641c8ee81732838",
            "528015b22f2f430d9ba58d631c81a691",
            "b86bd2cf927d4379bb30d913596885dc",
            "7b94a46f285b4189b8c8fd7703a3b56b",
            "7c2f51ced8d4473ab9b028895aaf4942",
            "cdc1c574dad04bf0b6765e845807370e",
            "675d0da1c68e44189f47961ea942ac07",
            "7a6c368e52b0455a976dfbc1199d1543",
            "7b78c4f6942a4a18a82da6cd113fbafa"
          ]
        },
        "id": "VzMLmLP86Ub-",
        "outputId": "d701cab3-07d8-4601-8135-659757ac6c7c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6e7f9b27d484b33bbd1eef006f742c2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Upload your dataset\n",
        "\n",
        "Add your data set to the root directory in the Colab under the name train.csv. The AutoTrain command will look for your data there under that name.\n",
        "\n",
        "#### Don't have a data set and want to try finetuning on an example data set?\n",
        "If you don't have a dataset you can run these commands below to get an example data set and save it to train.csv"
      ],
      "metadata": {
        "id": "qY932JBNZmtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/joshbickett/finetune-llama-2.git\n",
        "%cd finetune-llama-2\n",
        "%mv train.csv ../train.csv\n",
        "%cd .."
      ],
      "metadata": {
        "id": "JxTn4r_YZdkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b7a04cf-6a8a-44ed-f8c3-b0889f18133e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'finetune-llama-2'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 70 (delta 38), reused 48 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (70/70), 25.13 KiB | 12.57 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n",
            "/content/finetune-llama-2\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NUb-rkeoZzZ6",
        "outputId": "31df8523-6260-43da-95c8-be46fa4a8ea7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Concept  \\\n",
              "0                 A cactus at a dance party   \n",
              "1                   A robot on a first date   \n",
              "2                A snail at a speed contest   \n",
              "3                A penguin at a beach party   \n",
              "4                     A cloud in a bad mood   \n",
              "..                                      ...   \n",
              "112      A donut feeling the hole emptiness   \n",
              "113     A pineapple with a prickly attitude   \n",
              "114  A calculator crunching life's problems   \n",
              "115             A kite reaching new heights   \n",
              "116            A teddy bear feeling stuffed   \n",
              "\n",
              "                              Funny Description Prompt  \\\n",
              "0    A cactus, wearing disco lights and surrounded ...   \n",
              "1    A robot, with a bouquet of USB cables, nervous...   \n",
              "2    A snail, with a mini rocket booster, confident...   \n",
              "3    A penguin, with sunscreen and a surfboard, try...   \n",
              "4    A cloud, grumbling and dropping mini lightning...   \n",
              "..                                                 ...   \n",
              "112  A donut, in existential bakery therapy, ponder...   \n",
              "113  A pineapple, in a prickly personality class, s...   \n",
              "114  A calculator, at a problem-solving workshop, c...   \n",
              "115  A kite, in an altitude adjustment session, unt...   \n",
              "116  A teddy bear, in a fluff mindfulness group, em...   \n",
              "\n",
              "                                                  text  \n",
              "0    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "1    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "2    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "3    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "4    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "..                                                 ...  \n",
              "112  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "113  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "114  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "115  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "116  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "\n",
              "[117 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7352b86-cbbc-497b-9502-0367c8f88ff5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Concept</th>\n",
              "      <th>Funny Description Prompt</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A cactus at a dance party</td>\n",
              "      <td>A cactus, wearing disco lights and surrounded ...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A robot on a first date</td>\n",
              "      <td>A robot, with a bouquet of USB cables, nervous...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A snail at a speed contest</td>\n",
              "      <td>A snail, with a mini rocket booster, confident...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A penguin at a beach party</td>\n",
              "      <td>A penguin, with sunscreen and a surfboard, try...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A cloud in a bad mood</td>\n",
              "      <td>A cloud, grumbling and dropping mini lightning...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>A donut feeling the hole emptiness</td>\n",
              "      <td>A donut, in existential bakery therapy, ponder...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>A pineapple with a prickly attitude</td>\n",
              "      <td>A pineapple, in a prickly personality class, s...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>A calculator crunching life's problems</td>\n",
              "      <td>A calculator, at a problem-solving workshop, c...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>A kite reaching new heights</td>\n",
              "      <td>A kite, in an altitude adjustment session, unt...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>A teddy bear feeling stuffed</td>\n",
              "      <td>A teddy bear, in a fluff mindfulness group, em...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7352b86-cbbc-497b-9502-0367c8f88ff5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7352b86-cbbc-497b-9502-0367c8f88ff5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7352b86-cbbc-497b-9502-0367c8f88ff5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-64d10eb9-7cfa-4cfa-aa43-a5485d5dae83\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64d10eb9-7cfa-4cfa-aa43-a5485d5dae83')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-64d10eb9-7cfa-4cfa-aa43-a5485d5dae83 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b5b64b68-80a7-4219-b8a9-aa6ddbaea1bf\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b5b64b68-80a7-4219-b8a9-aa6ddbaea1bf button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'][15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3mr4WrwHZ0pv",
        "outputId": "62b16cca-17ca-4285-a6f2-dad4cf35bfad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'###Human:\\nGenerate a midjourney prompt for A book on a mystery adventure\\n\\n###Assistant:\\nA book, wearing detective glasses, flipping through its own pages, trying to solve the cliffhanger it was left on.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Overview of AutoTrain command\n",
        "\n",
        "#### Short overview of what the command flags do.\n",
        "\n",
        "- `!autotrain`: Command executed in environments like a Jupyter notebook to run shell commands directly. `autotrain` is an automatic training utility.\n",
        "\n",
        "- `llm`: A sub-command or argument specifying the type of task\n",
        "\n",
        "- `--train`: Initiates the training process.\n",
        "\n",
        "- `--project_name`: Sets the name of the project\n",
        "\n",
        "- `--model abhishek/llama-2-7b-hf-small-shards`: Specifies original model that is hosted on Hugging Face named \"llama-2-7b-hf-small-shards\" under the \"abhishek\".\n",
        "\n",
        "- `--data_path .`: The path to the dataset for training. The \".\" refers to the current directory. The `train.csv` file needs to be located in this directory.\n",
        "\n",
        "- `--use_int4`: Use of INT4 quantization to reduce model size and speed up inference times at the cost of some precision.\n",
        "\n",
        "- `--learning_rate 2e-4`: Sets the learning rate for training to 0.0002.\n",
        "\n",
        "- `--train_batch_size 12`: Sets the batch size for training to 12.\n",
        "\n",
        "- `--num_train_epochs 3`: The training process will iterate over the dataset 3 times.\n",
        "\n",
        "### Steps needed before running\n",
        "Go to the `!autotrain` code cell below and update it by following the steps below:\n",
        "\n",
        "1. After `--project_name` replace `*enter-a-project-name*` with the name that you'd like to call the project\n",
        "2. After `--repo_id` replace `*username*/*repository*`. Replace `*username*` with your Hugging Face username and `*repository*` with the repository name you'd like it to be created under. You don't need to create this repository before hand, it will automatically be created and uploaded once the training is completed.\n",
        "3. Confirm that `train.csv` is in the root directory in the Colab. The `--data_path .` flag will make it so that AutoTrain looks for your data there.\n",
        "4. Make sure to add the LoRA Target Modules to be trained `--target-modules q_proj, v_proj`\n",
        "5. Once you've made these changes you're all set, run the command below!"
      ],
      "metadata": {
        "id": "LEFbHxoPaDE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain llm --train --project-name mistral-7b-mj-finetuned_en --model filipealmeida/Mistral-7B-Instruct-v0.1-sharded --data-path . --use-peft --quantization int4 --lr 2e-4 --batch-size 12 --epochs 3 --trainer sft --target_modules q_proj,v_proj --push-to-hub --token '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' --repo-id Swapnilg915/mistral-7b-mj-finetuned_en"
      ],
      "metadata": {
        "id": "wFS31VJsZ-pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f0453a-f98c-426c-838e-ecdd7043de9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Running LLM\u001b[0m\n",
            "> \u001b[1mINFO    Params: Namespace(version=False, text_column='text', rejected_text_column='rejected', prompt_text_column='prompt', model_ref=None, warmup_ratio=0.1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.0, max_grad_norm=1.0, add_eos_token=False, block_size=-1, peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, mixed_precision=None, quantization='int4', model_max_length=1024, trainer='sft', target_modules='q_proj,v_proj', merge_adapter=False, use_flash_attention_2=False, dpo_beta=0.1, apply_chat_template=False, padding=None, train=True, deploy=False, inference=False, username=None, backend='local-cli', token='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', repo_id='Swapnilg915/mistral-7b-mj-finetuned_en', push_to_hub=True, model='filipealmeida/Mistral-7B-Instruct-v0.1-sharded', project_name='mistral-7b-mj-finetuned_en', seed=42, epochs=3, gradient_accumulation=1, disable_gradient_checkpointing=False, lr=0.0002, log='none', data_path='.', train_split='train', valid_split=None, batch_size=12, func=<function run_llm_command_factory at 0x7d70cc7e9ab0>)\u001b[0m\n",
            "> \u001b[1mINFO    Dataset: mistral-7b-mj-finetuned_en (lm_training)\n",
            "Train data: ['./train.csv']\n",
            "Valid data: []\n",
            "Column mapping: {'text': 'text', 'rejected_text': 'rejected', 'prompt': 'prompt'}\n",
            "\u001b[0m\n",
            "\rSaving the dataset (0/1 shards):   0% 0/117 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 117/117 [00:00<00:00, 20784.99 examples/s]\rSaving the dataset (1/1 shards): 100% 117/117 [00:00<00:00, 20332.86 examples/s]\n",
            "\rSaving the dataset (0/1 shards):   0% 0/117 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 117/117 [00:00<00:00, 49589.08 examples/s]\rSaving the dataset (1/1 shards): 100% 117/117 [00:00<00:00, 46621.09 examples/s]\n",
            "> \u001b[1mINFO    Starting local training...\u001b[0m\n",
            "> \u001b[1mINFO    {\"model\":\"filipealmeida/Mistral-7B-Instruct-v0.1-sharded\",\"project_name\":\"mistral-7b-mj-finetuned_en\",\"data_path\":\"mistral-7b-mj-finetuned_en/autotrain-data\",\"train_split\":\"train\",\"valid_split\":null,\"add_eos_token\":false,\"block_size\":-1,\"model_max_length\":1024,\"padding\":null,\"trainer\":\"sft\",\"use_flash_attention_2\":false,\"log\":\"none\",\"disable_gradient_checkpointing\":false,\"logging_steps\":-1,\"evaluation_strategy\":\"epoch\",\"save_total_limit\":1,\"save_strategy\":\"epoch\",\"auto_find_batch_size\":false,\"mixed_precision\":null,\"lr\":0.0002,\"epochs\":3,\"batch_size\":12,\"warmup_ratio\":0.1,\"gradient_accumulation\":1,\"optimizer\":\"adamw_torch\",\"scheduler\":\"linear\",\"weight_decay\":0.0,\"max_grad_norm\":1.0,\"seed\":42,\"apply_chat_template\":false,\"quantization\":\"int4\",\"target_modules\":\"q_proj,v_proj\",\"merge_adapter\":false,\"peft\":true,\"lora_r\":16,\"lora_alpha\":32,\"lora_dropout\":0.05,\"model_ref\":null,\"dpo_beta\":0.1,\"prompt_text_column\":\"autotrain_prompt\",\"text_column\":\"autotrain_text\",\"rejected_text_column\":\"autotrain_rejected_text\",\"push_to_hub\":true,\"repo_id\":\"Swapnilg915/mistral-7b-mj-finetuned_en\",\"username\":null,\"token\":\"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\"}\u001b[0m\n",
            "> \u001b[1mINFO    ['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'mistral-7b-mj-finetuned_en/training_params.json']\u001b[0m\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
            "  warnings.warn(\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 21:35:27\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mloading dataset from disk\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 21:35:27\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mTrain data: Dataset({\n",
            "    features: ['Concept', 'Funny Description Prompt', 'autotrain_text'],\n",
            "    num_rows: 117\n",
            "})\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 21:35:27\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mValid data: None\u001b[0m\n",
            "tokenizer_config.json: 100% 1.47k/1.47k [00:00<00:00, 9.06MB/s]\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 53.7MB/s]\n",
            "tokenizer.json: 100% 1.80M/1.80M [00:00<00:00, 7.40MB/s]\n",
            "special_tokens_map.json: 100% 72.0/72.0 [00:00<00:00, 497kB/s]\n",
            "config.json: 100% 665/665 [00:00<00:00, 3.58MB/s]\n",
            "pytorch_model.bin.index.json: 100% 23.9k/23.9k [00:00<00:00, 79.2MB/s]\n",
            "Downloading shards:   0% 0/8 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00008.bin:   0% 0.00/1.89G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:   3% 52.4M/1.89G [00:00<00:04, 449MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:   6% 105M/1.89G [00:00<00:03, 489MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00008.bin:   9% 168M/1.89G [00:00<00:03, 509MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  12% 231M/1.89G [00:00<00:03, 517MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  16% 294M/1.89G [00:00<00:03, 522MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  19% 357M/1.89G [00:00<00:02, 525MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  22% 419M/1.89G [00:00<00:02, 528MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  26% 482M/1.89G [00:00<00:02, 528MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  29% 545M/1.89G [00:01<00:02, 529MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  32% 608M/1.89G [00:01<00:02, 528MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  36% 671M/1.89G [00:01<00:02, 530MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  39% 734M/1.89G [00:01<00:02, 530MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  42% 797M/1.89G [00:01<00:02, 531MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  46% 860M/1.89G [00:01<00:01, 529MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  49% 923M/1.89G [00:01<00:01, 506MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  52% 975M/1.89G [00:01<00:01, 501MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  54% 1.03G/1.89G [00:01<00:01, 499MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  57% 1.08G/1.89G [00:02<00:01, 500MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  60% 1.13G/1.89G [00:02<00:01, 502MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  63% 1.18G/1.89G [00:02<00:01, 498MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  65% 1.24G/1.89G [00:02<00:01, 496MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  68% 1.29G/1.89G [00:02<00:01, 497MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  71% 1.34G/1.89G [00:02<00:01, 485MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  74% 1.39G/1.89G [00:02<00:01, 477MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  77% 1.45G/1.89G [00:02<00:00, 468MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  79% 1.50G/1.89G [00:02<00:00, 479MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  83% 1.56G/1.89G [00:03<00:00, 493MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  85% 1.61G/1.89G [00:03<00:00, 501MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  88% 1.67G/1.89G [00:03<00:00, 506MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  91% 1.72G/1.89G [00:03<00:00, 511MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  94% 1.77G/1.89G [00:03<00:00, 505MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  97% 1.82G/1.89G [00:03<00:00, 501MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin: 100% 1.89G/1.89G [00:03<00:00, 505MB/s]\n",
            "Downloading shards:  12% 1/8 [00:04<00:28,  4.02s/it]\n",
            "pytorch_model-00002-of-00008.bin:   0% 0.00/1.95G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:   3% 52.4M/1.95G [00:00<00:04, 450MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:   5% 105M/1.95G [00:00<00:03, 474MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00008.bin:   8% 157M/1.95G [00:00<00:03, 480MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  11% 210M/1.95G [00:00<00:04, 431MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  13% 262M/1.95G [00:00<00:06, 258MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  16% 304M/1.95G [00:01<00:06, 235MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  17% 336M/1.95G [00:01<00:07, 227MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  19% 367M/1.95G [00:01<00:06, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  21% 409M/1.95G [00:01<00:05, 272MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  23% 440M/1.95G [00:01<00:05, 270MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  25% 482M/1.95G [00:01<00:04, 296MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  27% 524M/1.95G [00:01<00:04, 316MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  29% 566M/1.95G [00:01<00:04, 314MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  31% 608M/1.95G [00:02<00:04, 325MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  33% 650M/1.95G [00:02<00:03, 325MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  36% 692M/1.95G [00:02<00:03, 322MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  38% 744M/1.95G [00:02<00:03, 335MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  40% 786M/1.95G [00:02<00:03, 338MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  43% 828M/1.95G [00:02<00:03, 338MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  45% 870M/1.95G [00:02<00:03, 309MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  47% 912M/1.95G [00:02<00:03, 314MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  49% 954M/1.95G [00:03<00:02, 334MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  51% 996M/1.95G [00:03<00:02, 341MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  53% 1.04G/1.95G [00:03<00:02, 335MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  55% 1.08G/1.95G [00:03<00:02, 349MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  58% 1.12G/1.95G [00:03<00:02, 340MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  60% 1.16G/1.95G [00:03<00:02, 341MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  62% 1.22G/1.95G [00:03<00:01, 375MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  65% 1.27G/1.95G [00:03<00:01, 398MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  68% 1.32G/1.95G [00:04<00:01, 423MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  71% 1.37G/1.95G [00:04<00:01, 443MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  73% 1.43G/1.95G [00:04<00:01, 458MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  76% 1.48G/1.95G [00:04<00:01, 466MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  79% 1.53G/1.95G [00:04<00:00, 471MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  81% 1.58G/1.95G [00:04<00:00, 475MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  84% 1.64G/1.95G [00:04<00:00, 387MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  86% 1.68G/1.95G [00:04<00:00, 325MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  88% 1.72G/1.95G [00:05<00:00, 307MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  91% 1.76G/1.95G [00:05<00:00, 290MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  92% 1.79G/1.95G [00:05<00:00, 295MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  94% 1.82G/1.95G [00:05<00:00, 293MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  95% 1.86G/1.95G [00:05<00:00, 294MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  97% 1.89G/1.95G [00:05<00:00, 297MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin: 100% 1.95G/1.95G [00:05<00:00, 330MB/s]\n",
            "Downloading shards:  25% 2/8 [00:10<00:31,  5.28s/it]\n",
            "pytorch_model-00003-of-00008.bin:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:   3% 52.4M/1.98G [00:00<00:03, 485MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:   6% 115M/1.98G [00:00<00:03, 511MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00008.bin:   9% 178M/1.98G [00:00<00:03, 519MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  12% 231M/1.98G [00:00<00:03, 475MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  14% 283M/1.98G [00:00<00:03, 439MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  17% 336M/1.98G [00:00<00:04, 387MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  19% 377M/1.98G [00:00<00:04, 383MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  21% 419M/1.98G [00:01<00:04, 366MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  23% 461M/1.98G [00:01<00:04, 344MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  25% 503M/1.98G [00:01<00:05, 290MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  27% 535M/1.98G [00:01<00:05, 271MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  29% 566M/1.98G [00:01<00:05, 276MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  31% 608M/1.98G [00:01<00:04, 289MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  33% 650M/1.98G [00:01<00:04, 311MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  35% 692M/1.98G [00:01<00:03, 334MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  38% 744M/1.98G [00:02<00:03, 379MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  40% 797M/1.98G [00:02<00:02, 412MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  43% 849M/1.98G [00:02<00:02, 430MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  46% 902M/1.98G [00:02<00:02, 438MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  48% 954M/1.98G [00:02<00:02, 448MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  51% 1.01G/1.98G [00:02<00:02, 458MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  53% 1.06G/1.98G [00:02<00:01, 471MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  56% 1.11G/1.98G [00:02<00:01, 486MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  59% 1.17G/1.98G [00:02<00:01, 499MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  62% 1.23G/1.98G [00:03<00:01, 503MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  65% 1.28G/1.98G [00:03<00:01, 505MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  67% 1.33G/1.98G [00:03<00:01, 509MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  70% 1.38G/1.98G [00:03<00:01, 513MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  73% 1.45G/1.98G [00:03<00:01, 518MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  76% 1.50G/1.98G [00:03<00:00, 517MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  78% 1.55G/1.98G [00:03<00:00, 517MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  81% 1.60G/1.98G [00:03<00:00, 516MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  84% 1.66G/1.98G [00:03<00:00, 517MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  86% 1.71G/1.98G [00:04<00:00, 408MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  89% 1.76G/1.98G [00:04<00:00, 273MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  92% 1.81G/1.98G [00:04<00:00, 299MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  94% 1.86G/1.98G [00:04<00:00, 274MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  96% 1.90G/1.98G [00:04<00:00, 255MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  97% 1.93G/1.98G [00:05<00:00, 238MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin: 100% 1.98G/1.98G [00:05<00:00, 368MB/s]\n",
            "Downloading shards:  38% 3/8 [00:15<00:27,  5.45s/it]\n",
            "pytorch_model-00004-of-00008.bin:   0% 0.00/1.95G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:   2% 31.5M/1.95G [00:00<00:08, 227MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:   3% 62.9M/1.95G [00:00<00:08, 229MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:   6% 115M/1.95G [00:00<00:05, 321MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00008.bin:   9% 168M/1.95G [00:00<00:04, 384MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  11% 210M/1.95G [00:00<00:05, 306MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  13% 252M/1.95G [00:00<00:06, 255MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  15% 283M/1.95G [00:01<00:07, 235MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  16% 315M/1.95G [00:01<00:06, 238MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  18% 357M/1.95G [00:01<00:05, 275MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  20% 398M/1.95G [00:01<00:05, 293MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  23% 440M/1.95G [00:01<00:04, 309MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  25% 482M/1.95G [00:01<00:04, 335MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  27% 535M/1.95G [00:01<00:03, 375MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  30% 587M/1.95G [00:01<00:03, 404MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  33% 640M/1.95G [00:01<00:03, 422MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  36% 692M/1.95G [00:02<00:02, 439MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  38% 744M/1.95G [00:02<00:02, 451MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  41% 797M/1.95G [00:02<00:02, 448MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  44% 849M/1.95G [00:02<00:02, 395MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  46% 891M/1.95G [00:02<00:02, 367MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  48% 933M/1.95G [00:02<00:02, 357MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  50% 975M/1.95G [00:02<00:02, 341MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  52% 1.02G/1.95G [00:03<00:02, 336MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  54% 1.06G/1.95G [00:03<00:02, 316MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  57% 1.10G/1.95G [00:03<00:02, 317MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  59% 1.14G/1.95G [00:03<00:02, 309MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  61% 1.18G/1.95G [00:03<00:02, 311MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  62% 1.22G/1.95G [00:03<00:02, 299MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  64% 1.25G/1.95G [00:03<00:02, 298MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  66% 1.28G/1.95G [00:03<00:02, 298MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  68% 1.32G/1.95G [00:04<00:02, 299MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  70% 1.35G/1.95G [00:04<00:02, 296MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  71% 1.38G/1.95G [00:04<00:01, 293MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  73% 1.42G/1.95G [00:04<00:01, 293MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  74% 1.45G/1.95G [00:04<00:01, 288MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  77% 1.49G/1.95G [00:04<00:01, 301MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  79% 1.53G/1.95G [00:04<00:01, 310MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  80% 1.56G/1.95G [00:04<00:01, 303MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  82% 1.59G/1.95G [00:04<00:01, 291MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  84% 1.63G/1.95G [00:05<00:01, 286MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  85% 1.66G/1.95G [00:05<00:01, 280MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  87% 1.69G/1.95G [00:05<00:00, 282MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  88% 1.72G/1.95G [00:05<00:00, 282MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  91% 1.76G/1.95G [00:05<00:00, 304MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  93% 1.80G/1.95G [00:05<00:00, 323MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  95% 1.86G/1.95G [00:05<00:00, 370MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin: 100% 1.95G/1.95G [00:07<00:00, 276MB/s]\n",
            "Downloading shards:  50% 4/8 [00:23<00:24,  6.18s/it]\n",
            "pytorch_model-00005-of-00008.bin:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:   3% 52.4M/1.98G [00:00<00:04, 471MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:   5% 105M/1.98G [00:00<00:03, 501MB/s] \u001b[A\n",
            "pytorch_model-00005-of-00008.bin:   8% 168M/1.98G [00:00<00:03, 516MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  11% 220M/1.98G [00:00<00:03, 519MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  14% 283M/1.98G [00:00<00:03, 522MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  17% 336M/1.98G [00:00<00:05, 295MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  19% 377M/1.98G [00:00<00:05, 316MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  21% 419M/1.98G [00:01<00:05, 311MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  23% 461M/1.98G [00:01<00:05, 302MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  25% 503M/1.98G [00:01<00:05, 284MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  27% 535M/1.98G [00:01<00:05, 278MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  29% 566M/1.98G [00:01<00:04, 283MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  30% 598M/1.98G [00:01<00:04, 278MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  32% 629M/1.98G [00:01<00:04, 274MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  33% 661M/1.98G [00:02<00:04, 271MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  35% 692M/1.98G [00:02<00:04, 264MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  37% 724M/1.98G [00:02<00:04, 260MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  38% 755M/1.98G [00:02<00:04, 254MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  40% 786M/1.98G [00:02<00:04, 247MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  41% 818M/1.98G [00:02<00:04, 239MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  43% 849M/1.98G [00:02<00:04, 228MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  44% 881M/1.98G [00:03<00:04, 222MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  46% 912M/1.98G [00:03<00:04, 215MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  48% 944M/1.98G [00:03<00:04, 208MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  49% 975M/1.98G [00:03<00:04, 202MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  50% 996M/1.98G [00:03<00:04, 197MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  51% 1.02G/1.98G [00:03<00:04, 195MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  52% 1.04G/1.98G [00:03<00:04, 193MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  53% 1.06G/1.98G [00:03<00:04, 197MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  55% 1.08G/1.98G [00:04<00:04, 194MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  56% 1.11G/1.98G [00:04<00:03, 218MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  58% 1.15G/1.98G [00:04<00:03, 259MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  60% 1.18G/1.98G [00:04<00:04, 173MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  62% 1.24G/1.98G [00:04<00:03, 239MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  65% 1.28G/1.98G [00:04<00:02, 270MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  67% 1.33G/1.98G [00:04<00:02, 323MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  69% 1.37G/1.98G [00:05<00:01, 334MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  72% 1.42G/1.98G [00:05<00:01, 334MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  74% 1.46G/1.98G [00:05<00:01, 324MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  76% 1.50G/1.98G [00:05<00:01, 316MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  78% 1.55G/1.98G [00:05<00:01, 357MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  81% 1.59G/1.98G [00:05<00:01, 361MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  83% 1.64G/1.98G [00:05<00:00, 374MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  85% 1.69G/1.98G [00:05<00:00, 396MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  88% 1.74G/1.98G [00:06<00:00, 411MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  91% 1.79G/1.98G [00:06<00:00, 423MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  93% 1.85G/1.98G [00:06<00:00, 433MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  96% 1.90G/1.98G [00:06<00:00, 426MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin: 100% 1.98G/1.98G [00:06<00:00, 302MB/s]\n",
            "Downloading shards:  62% 5/8 [00:29<00:19,  6.42s/it]\n",
            "pytorch_model-00006-of-00008.bin:   0% 0.00/1.95G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:   1% 21.0M/1.95G [00:00<00:10, 179MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:   3% 52.4M/1.95G [00:00<00:08, 224MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:   5% 94.4M/1.95G [00:00<00:06, 297MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:   7% 136M/1.95G [00:00<00:05, 334MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00008.bin:   9% 178M/1.95G [00:00<00:04, 360MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  11% 220M/1.95G [00:00<00:04, 375MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  13% 262M/1.95G [00:00<00:04, 381MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  16% 304M/1.95G [00:00<00:04, 389MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  18% 346M/1.95G [00:00<00:04, 395MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  20% 398M/1.95G [00:01<00:03, 412MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  23% 451M/1.95G [00:01<00:03, 428MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  26% 503M/1.95G [00:01<00:03, 436MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  29% 556M/1.95G [00:01<00:03, 443MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  31% 608M/1.95G [00:01<00:03, 446MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  34% 661M/1.95G [00:01<00:02, 434MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  37% 713M/1.95G [00:01<00:02, 434MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  39% 765M/1.95G [00:01<00:02, 437MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  42% 818M/1.95G [00:02<00:02, 438MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  45% 870M/1.95G [00:02<00:02, 438MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  47% 923M/1.95G [00:02<00:02, 440MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  50% 975M/1.95G [00:02<00:02, 445MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  53% 1.03G/1.95G [00:02<00:02, 445MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  55% 1.08G/1.95G [00:02<00:01, 444MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  58% 1.13G/1.95G [00:02<00:01, 444MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  61% 1.18G/1.95G [00:02<00:01, 440MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  64% 1.24G/1.95G [00:02<00:01, 453MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  66% 1.29G/1.95G [00:03<00:01, 464MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  69% 1.34G/1.95G [00:03<00:01, 472MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  72% 1.39G/1.95G [00:03<00:01, 477MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  74% 1.45G/1.95G [00:03<00:01, 483MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  77% 1.50G/1.95G [00:03<00:00, 473MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  80% 1.55G/1.95G [00:03<00:00, 478MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  82% 1.60G/1.95G [00:03<00:00, 481MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  85% 1.66G/1.95G [00:03<00:00, 418MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  88% 1.71G/1.95G [00:04<00:00, 382MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  90% 1.75G/1.95G [00:04<00:00, 367MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  92% 1.79G/1.95G [00:04<00:00, 350MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  94% 1.84G/1.95G [00:04<00:00, 336MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  96% 1.88G/1.95G [00:04<00:00, 324MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin: 100% 1.95G/1.95G [00:04<00:00, 401MB/s]\n",
            "Downloading shards:  75% 6/8 [00:35<00:11,  5.98s/it]\n",
            "pytorch_model-00007-of-00008.bin:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:   2% 41.9M/1.98G [00:00<00:05, 365MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:   5% 94.4M/1.98G [00:00<00:04, 437MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:   7% 147M/1.98G [00:00<00:03, 459MB/s] \u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  10% 199M/1.98G [00:00<00:03, 473MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  13% 252M/1.98G [00:00<00:05, 335MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  15% 294M/1.98G [00:00<00:05, 286MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  17% 336M/1.98G [00:01<00:06, 250MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  19% 367M/1.98G [00:01<00:07, 224MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  20% 398M/1.98G [00:01<00:07, 204MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  22% 430M/1.98G [00:01<00:08, 194MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  23% 451M/1.98G [00:01<00:08, 181MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  24% 472M/1.98G [00:01<00:08, 176MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  26% 514M/1.98G [00:02<00:06, 214MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  28% 556M/1.98G [00:02<00:05, 249MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  30% 598M/1.98G [00:02<00:04, 286MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  33% 650M/1.98G [00:02<00:03, 335MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  35% 703M/1.98G [00:02<00:03, 371MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  38% 755M/1.98G [00:02<00:03, 405MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  41% 807M/1.98G [00:02<00:02, 426MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  43% 860M/1.98G [00:02<00:02, 438MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  46% 912M/1.98G [00:02<00:02, 455MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  49% 965M/1.98G [00:03<00:02, 468MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  51% 1.02G/1.98G [00:03<00:02, 475MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  54% 1.07G/1.98G [00:03<00:01, 471MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  57% 1.12G/1.98G [00:03<00:02, 420MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  59% 1.17G/1.98G [00:03<00:02, 372MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  61% 1.22G/1.98G [00:03<00:02, 351MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  64% 1.26G/1.98G [00:03<00:02, 326MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  66% 1.30G/1.98G [00:04<00:02, 309MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  68% 1.34G/1.98G [00:04<00:02, 297MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  69% 1.37G/1.98G [00:04<00:02, 287MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  71% 1.41G/1.98G [00:04<00:02, 283MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  73% 1.44G/1.98G [00:04<00:01, 273MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  74% 1.47G/1.98G [00:04<00:01, 264MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  76% 1.50G/1.98G [00:04<00:01, 263MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  77% 1.53G/1.98G [00:04<00:01, 256MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  79% 1.56G/1.98G [00:05<00:02, 170MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  82% 1.61G/1.98G [00:05<00:01, 231MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  84% 1.66G/1.98G [00:05<00:01, 265MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  86% 1.71G/1.98G [00:05<00:00, 308MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  89% 1.76G/1.98G [00:05<00:00, 347MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  92% 1.81G/1.98G [00:05<00:00, 377MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  94% 1.87G/1.98G [00:05<00:00, 399MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  97% 1.92G/1.98G [00:06<00:00, 415MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin: 100% 1.98G/1.98G [00:06<00:00, 318MB/s]\n",
            "Downloading shards:  88% 7/8 [00:41<00:06,  6.15s/it]\n",
            "pytorch_model-00008-of-00008.bin:   0% 0.00/816M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:   5% 41.9M/816M [00:00<00:02, 385MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  10% 83.9M/816M [00:00<00:01, 379MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  15% 126M/816M [00:00<00:01, 380MB/s] \u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  21% 168M/816M [00:00<00:01, 382MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  27% 220M/816M [00:00<00:01, 408MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  33% 273M/816M [00:00<00:01, 422MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  40% 325M/816M [00:00<00:01, 440MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  46% 377M/816M [00:00<00:00, 452MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  53% 430M/816M [00:01<00:00, 461MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  59% 482M/816M [00:01<00:00, 468MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  66% 535M/816M [00:01<00:00, 472MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  72% 587M/816M [00:01<00:00, 482MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  78% 640M/816M [00:01<00:00, 482MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  85% 692M/816M [00:01<00:00, 481MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  91% 744M/816M [00:01<00:00, 483MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin: 100% 816M/816M [00:01<00:00, 452MB/s]\n",
            "Downloading shards: 100% 8/8 [00:43<00:00,  5.46s/it]\n",
            "Loading checkpoint shards:   0% 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Loading checkpoint shards: 100% 8/8 [00:06<00:00,  1.28it/s]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 617kB/s]\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 21:36:27\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mUsing block size 1024\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 21:36:27\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m339\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:247: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "  0% 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.6708, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.1}\n",
            "  3% 1/30 [00:14<07:06, 14.70s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.6708, 'learning_rate': 0.00013333333333333334, 'epoch': 1.1}\n",
            "  7% 2/30 [00:28<06:31, 14.00s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.619, 'learning_rate': 0.0002, 'epoch': 2.1}\n",
            "{'train_runtime': 41.9666, 'train_samples_per_second': 8.364, 'train_steps_per_second': 0.715, 'train_loss': 1.6535237232844036, 'epoch': 2.1}\n",
            " 10% 3/30 [00:41<06:17, 13.99s/it]\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 21:37:10\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m477\u001b[0m - \u001b[1mFinished training, saving model...\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 21:37:10\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m510\u001b[0m - \u001b[1mPushing model to hub...\u001b[0m\n",
            "\u001b[31m\u001b[1m❌ ERROR \u001b[0m | \u001b[32m2024-01-31 21:37:11\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m91\u001b[0m - \u001b[31m\u001b[1mtrain has failed due to an exception: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 286, in hf_raise_for_status\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 1021, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 409 Client Error: Conflict for url: https://huggingface.co/api/repos/create\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autotrain/trainers/common.py\", line 88, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autotrain/trainers/clm/__main__.py\", line 513, in train\n",
            "    api.create_repo(repo_id=config.repo_id, repo_type=\"model\", private=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 118, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\", line 3178, in create_repo\n",
            "    hf_raise_for_status(r)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 333, in hf_raise_for_status\n",
            "    raise HfHubHTTPError(str(e), response=response) from e\n",
            "huggingface_hub.utils._errors.HfHubHTTPError: 409 Client Error: Conflict for url: https://huggingface.co/api/repos/create (Request ID: Root=1-65babd86-3dcf341e3c6252fa26de57a8;ef56fc59-cb7a-4820-91c6-c89c1102eb68)\n",
            "\n",
            "You already created this model repo\n",
            "\u001b[0m\n",
            "\u001b[31m\u001b[1m❌ ERROR \u001b[0m | \u001b[32m2024-01-31 21:37:11\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mwrapper\u001b[0m:\u001b[36m92\u001b[0m - \u001b[31m\u001b[1m409 Client Error: Conflict for url: https://huggingface.co/api/repos/create (Request ID: Root=1-65babd86-3dcf341e3c6252fa26de57a8;ef56fc59-cb7a-4820-91c6-c89c1102eb68)\n",
            "\n",
            "You already created this model repo\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Completed 🎉\n",
        "After the command above is completed your Model will be uploaded to Hugging Face.\n",
        "\n",
        "#### Learn more about AutoTrain (optional)\n",
        "If you want to learn more about what command-line flags are available"
      ],
      "metadata": {
        "id": "gEf6G0iPc0Nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Inference Engine"
      ],
      "metadata": {
        "id": "FIoxuAEAfJ4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain llm -h"
      ],
      "metadata": {
        "id": "aYsYyXmrc0xu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a21db27-43d7-45b2-fc85-59f061c7317f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: autotrain <command> [<args>] llm [-h] [--text_column TEXT_COLUMN]\n",
            "                                        [--rejected_text_column REJECTED_TEXT_COLUMN]\n",
            "                                        [--prompt-text-column PROMPT_TEXT_COLUMN]\n",
            "                                        [--model-ref MODEL_REF] [--warmup_ratio WARMUP_RATIO]\n",
            "                                        [--optimizer OPTIMIZER] [--scheduler SCHEDULER]\n",
            "                                        [--weight_decay WEIGHT_DECAY]\n",
            "                                        [--max_grad_norm MAX_GRAD_NORM] [--add_eos_token]\n",
            "                                        [--block_size BLOCK_SIZE] [--peft] [--lora_r LORA_R]\n",
            "                                        [--lora_alpha LORA_ALPHA] [--lora_dropout LORA_DROPOUT]\n",
            "                                        [--logging_steps LOGGING_STEPS]\n",
            "                                        [--evaluation_strategy EVALUATION_STRATEGY]\n",
            "                                        [--save_total_limit SAVE_TOTAL_LIMIT]\n",
            "                                        [--save_strategy SAVE_STRATEGY] [--auto_find_batch_size]\n",
            "                                        [--mixed-precision MIXED_PRECISION]\n",
            "                                        [--quantization QUANTIZATION]\n",
            "                                        [--model_max_length MODEL_MAX_LENGTH] [--trainer TRAINER]\n",
            "                                        [--target_modules TARGET_MODULES] [--merge_adapter]\n",
            "                                        [--use_flash_attention_2] [--dpo-beta DPO_BETA]\n",
            "                                        [--apply_chat_template] [--padding PADDING] [--train]\n",
            "                                        [--deploy] [--inference] [--username USERNAME]\n",
            "                                        [--backend BACKEND] [--token TOKEN] [--repo-id REPO_ID]\n",
            "                                        [--push-to-hub] --model MODEL --project-name PROJECT_NAME\n",
            "                                        [--seed SEED] [--epochs EPOCHS]\n",
            "                                        [--gradient-accumulation GRADIENT_ACCUMULATION]\n",
            "                                        [--disable_gradient_checkpointing] [--lr LR] [--log LOG]\n",
            "                                        [--data-path DATA_PATH] [--train-split TRAIN_SPLIT]\n",
            "                                        [--valid-split VALID_SPLIT] [--batch-size BATCH_SIZE]\n",
            "\n",
            "✨ Run AutoTrain LLM\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --text_column TEXT_COLUMN, --text-column TEXT_COLUMN\n",
            "                        Text column to use\n",
            "  --rejected_text_column REJECTED_TEXT_COLUMN, --rejected-text-column REJECTED_TEXT_COLUMN\n",
            "                        Rejected text column to use\n",
            "  --prompt-text-column PROMPT_TEXT_COLUMN, --prompt-text-column PROMPT_TEXT_COLUMN\n",
            "                        Prompt text column to use\n",
            "  --model-ref MODEL_REF\n",
            "                        Reference model to use for DPO when not using PEFT\n",
            "  --warmup_ratio WARMUP_RATIO, --warmup-ratio WARMUP_RATIO\n",
            "                        Warmup proportion to use\n",
            "  --optimizer OPTIMIZER\n",
            "                        Optimizer to use\n",
            "  --scheduler SCHEDULER\n",
            "                        Scheduler to use\n",
            "  --weight_decay WEIGHT_DECAY, --weight-decay WEIGHT_DECAY\n",
            "                        Weight decay to use\n",
            "  --max_grad_norm MAX_GRAD_NORM, --max-grad-norm MAX_GRAD_NORM\n",
            "                        Max gradient norm to use\n",
            "  --add_eos_token, --add-eos-token\n",
            "                        Add EOS token to use\n",
            "  --block_size BLOCK_SIZE, --block-size BLOCK_SIZE\n",
            "                        Block size to use\n",
            "  --peft, --use-peft    Use PEFT\n",
            "  --lora_r LORA_R, --lora-r LORA_R\n",
            "                        Lora r to use\n",
            "  --lora_alpha LORA_ALPHA, --lora-alpha LORA_ALPHA\n",
            "                        Lora alpha to use\n",
            "  --lora_dropout LORA_DROPOUT, --lora-dropout LORA_DROPOUT\n",
            "                        Lora dropout to use\n",
            "  --logging_steps LOGGING_STEPS, --logging-steps LOGGING_STEPS\n",
            "                        Logging steps to use\n",
            "  --evaluation_strategy EVALUATION_STRATEGY, --evaluation-strategy EVALUATION_STRATEGY\n",
            "                        Evaluation strategy to use\n",
            "  --save_total_limit SAVE_TOTAL_LIMIT, --save-total-limit SAVE_TOTAL_LIMIT\n",
            "                        Save total limit to use\n",
            "  --save_strategy SAVE_STRATEGY, --save-strategy SAVE_STRATEGY\n",
            "                        Save strategy to use\n",
            "  --auto_find_batch_size, --auto-find-batch-size\n",
            "                        Auto find batch size True/False\n",
            "  --mixed-precision MIXED_PRECISION, --mixed-precision MIXED_PRECISION, --mp MIXED_PRECISION\n",
            "                        fp16, bf16, or None\n",
            "  --quantization QUANTIZATION, --quantization QUANTIZATION\n",
            "                        int4, int8, or None\n",
            "  --model_max_length MODEL_MAX_LENGTH, --max-len MODEL_MAX_LENGTH, --max-length MODEL_MAX_LENGTH\n",
            "                        Model max length to use\n",
            "  --trainer TRAINER     Trainer type to use\n",
            "  --target_modules TARGET_MODULES, --target-modules TARGET_MODULES\n",
            "                        Target modules to use\n",
            "  --merge_adapter, --merge-adapter\n",
            "                        Use this flag to merge PEFT adapter with the model\n",
            "  --use_flash_attention_2, --use-flash-attention-2, --use-fa2\n",
            "                        Use flash attention 2\n",
            "  --dpo-beta DPO_BETA, --dpo-beta DPO_BETA\n",
            "                        Beta for DPO trainer\n",
            "  --apply_chat_template, --apply-chat-template\n",
            "                        Apply chat template\n",
            "  --padding PADDING, --padding PADDING\n",
            "                        Padding side\n",
            "  --train               Train the model\n",
            "  --deploy              Deploy the model\n",
            "  --inference           Run inference\n",
            "  --username USERNAME   Hugging Face Hub Username\n",
            "  --backend BACKEND     Backend to use: default or spaces. Spaces backend requires push_to_hub and\n",
            "                        repo_id\n",
            "  --token TOKEN         Hub token\n",
            "  --repo-id REPO_ID     Hub repo id\n",
            "  --push-to-hub         Push to hub\n",
            "  --model MODEL         Model to use for training\n",
            "  --project-name PROJECT_NAME\n",
            "                        Output directory or repo id\n",
            "  --seed SEED           Seed\n",
            "  --epochs EPOCHS       Number of training epochs\n",
            "  --gradient-accumulation GRADIENT_ACCUMULATION\n",
            "                        Gradient accumulation steps\n",
            "  --disable_gradient_checkpointing, --disable-gradient-checkpointing, --disable-gc\n",
            "                        Disable gradient checkpointing\n",
            "  --lr LR               Learning rate\n",
            "  --log LOG             Use experiment tracking\n",
            "  --data-path DATA_PATH\n",
            "                        Train dataset to use\n",
            "  --train-split TRAIN_SPLIT\n",
            "                        Test dataset split to use\n",
            "  --valid-split VALID_SPLIT\n",
            "                        Validation dataset split to use\n",
            "  --batch-size BATCH_SIZE, --train-batch-size BATCH_SIZE\n",
            "                        Training batch size to use\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q peft  accelerate bitsandbytes safetensors"
      ],
      "metadata": {
        "id": "5m1ouhWhc2fr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import transformers\n",
        "adapters_name = \"Swapnilg915/mistral-7b-mj-finetuned\"\n",
        "model_name = \"filipealmeida/Mistral-7B-Instruct-v0.1-sharded\" #\"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "\n",
        "device = \"cuda\" # the device to load the model onto"
      ],
      "metadata": {
        "id": "8s-nDnnPc--U"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "id": "HosPywN_dEpl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "4655579000e849c2a7a283f453a812ae",
            "36fa4d3d148d43cfa2190879e093e9d8",
            "058c4e66ea924115b144400e9ae09528",
            "2d820267e6454430af2847b4b1d6d043",
            "52396ace5a754b75ab4c26b8c6c27353",
            "c7244221839445f1bb04d656f56f5642",
            "9852d295b5e54522b08579df26136af7",
            "9766b980e64d443882cd4dad681fd414",
            "17314a3cfb744a158ab4f39e17c6f506",
            "ebcc3601756d4529a96103f8a4c14987",
            "47f57d293cae4cc5909a97fba7bb73c1"
          ]
        },
        "id": "GtZx4CZUdt1f",
        "outputId": "659ba5d3-b123-4ca6-9047-ba80a93fa509"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4655579000e849c2a7a283f453a812ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Peft Model Loading with upload model"
      ],
      "metadata": {
        "id": "Uh5Xc0clfQkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PeftModel.from_pretrained(model, adapters_name)"
      ],
      "metadata": {
        "id": "Rt6sOPFVdvWX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "9b82782a1c214068ad05a22eb5391079",
            "69bcbf2fafb74c41940e7e1c63c35abd",
            "e854b7fab8124654913557b521f772fc",
            "e8299be6f35e4f0a86b2ba8b8c2ef71b",
            "4e2da159a6004203a79935db7aef0ce9",
            "fc802b45dc4046c6a54e0835b9bc7584",
            "740e9bbbfcb44f07beb4b54d64a00b46",
            "c36db8475a43420c984ec4b6943cc75b",
            "83ec6bd5fa4c474ea19305757ea435fd",
            "023721cb450f4b539674b4e6d268dd8a",
            "db1ec10d7ff64aadac4d673f177aa818",
            "29009715d9814b10b349dafed7d79c60",
            "7ec303570a5b476fab5653541c26b206",
            "6da50803adb14f89b739f977f1531c32",
            "9c218b8fc7e34e8bab2d89a22da74235",
            "d7fb6a2058bd4fbab636f3c363217241",
            "4204685db1104934ac78700244e80895",
            "6fb90a8159b844a2a5f1e82c863943f1",
            "7bb9d76e78e5491bba59e028af04ba07",
            "76cfdaee54274f5296f30497c226db8a",
            "5bef62e595d24899bc4476b2fe77fa1a",
            "99ec2d0024a34e9c82d6ed8a0c3a414c"
          ]
        },
        "outputId": "56590c36-f3f8-4f4c-955f-7172f251c286"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b82782a1c214068ad05a22eb5391079"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29009715d9814b10b349dafed7d79c60"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.bos_token_id = 1\n",
        "\n",
        "stop_token_ids = [0]\n",
        "\n",
        "print(f\"Successfully loaded the model {model_name} into memory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3OArVILeoZH",
        "outputId": "966b199f-6219-4081-999c-e8f140923209"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded the model filipealmeida/Mistral-7B-Instruct-v0.1-sharded into memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"[INST] generate a midjourney prompt for A person walks in the rain [/INST]\"\n",
        "\n",
        "encoded = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
        "model_input = encoded\n",
        "model.to(device)\n",
        "generated_ids = model.generate(**model_input, max_new_tokens=200, do_sample=True)\n",
        "decoded = tokenizer.batch_decode(generated_ids)\n",
        "print(decoded[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbOOX8cve0lR",
        "outputId": "a1722ea6-b7e1-4543-9b6b-15c4047c2bc0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1408: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] generate a midjourney prompt for A person walks in the rain [/INST] \"As the rain beats down on his umbrella, the protagonist finds himself lost in the city he thought he knew so well. Take him on a journey through the rainy landscape, leading him through unexpected twists and turns towards a surprising encounter.\"</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#streamlit\n"
      ],
      "metadata": {
        "id": "wPZmHPDF5Voh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcrM_vLZiBag",
        "outputId": "9e05c93c-903c-4429-cf15-ed0963e1ba64"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.30.0-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<8,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (7.0.1)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.0.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.23.4)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.9.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<8,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.17.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.41 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.30.0 validators-0.22.0 watchdog-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfU9qu81iEa4",
        "outputId": "4daaa777-e2f2-496e-bac7-56ae3150f034"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.4-py3-none-any.whl (803 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.3/803.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
            "  Downloading langchain_community-0.0.16-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
            "  Downloading langchain_core-0.1.17-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.85-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.4.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (3.7.1)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.16->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "autotrain-advanced 0.6.81 requires packaging==23.1, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.4 langchain-community-0.0.16 langchain-core-0.1.17 langsmith-0.0.85 marshmallow-3.20.2 mypy-extensions-1.0.0 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnC7Y-ksiJPW",
        "outputId": "73995aed-ee6d-41d6-8c64-1a5722bbef7c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (3.41.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.104.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.0.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.4.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.22.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.13.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio) (2.10.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.11.17)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "R2_v3aOlnfxD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_prompt(message, history):\n",
        "  prompt = \"<s>\"\n",
        "  for user_prompt, bot_response in history:\n",
        "    prompt += f\"[INST] {user_prompt} [/INST]\"\n",
        "    prompt += f\" {bot_response}</s> \"\n",
        "  prompt += f\"[INST] {message} [/INST]\"\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "g8XyC2NXoEjb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_one(prompt, history):\n",
        "  print(\"\\n prompt : \", prompt)\n",
        "  # formatted_prompt = format_prompt(prompt, history)\n",
        "  encoded = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
        "  model_input = encoded\n",
        "  model.to(device)\n",
        "  generated_ids = model.generate(**model_input, max_new_tokens=200, do_sample=True)\n",
        "  decoded = tokenizer.batch_decode(generated_ids)\n",
        "  response = decoded[0].replace(\"<s>\", \"\").replace(\"</s>\", \"\").replace(\"[INST]\", \"\").replace(\"[/INST]\", \"\")\n",
        "  print(\"response : \", response)\n",
        "  return response"
      ],
      "metadata": {
        "id": "15l9OeJ-qQJK"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.ChatInterface(\n",
        "        generate_one\n",
        "    )\n",
        "\n",
        "demo.queue().launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "6LJyoeHJqgbV",
        "outputId": "db8576d1-3b2e-4479-edc0-2394c3806078"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://6126eaee8b326f631e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6126eaee8b326f631e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " prompt :  what is the capital of Norway\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1408: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response :  what is the capital of Norway?\n",
            "Answer: Oslo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " prompt :  what is the capital of UAE?\n",
            "response :  what is the capital of UAE?\n",
            "The capital of UAE is Abu Dhabi.\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7862 <> https://6126eaee8b326f631e.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "laNLLxBrn1BI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}