{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a6f140c23664eb9b41d3fdfaecd621c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d0707c43c1943719665a8fa4402abea",
              "IPY_MODEL_5bf07d4416f24b469c4370b919754f4e",
              "IPY_MODEL_6190854c87b54fac8df857e08acfc8c1",
              "IPY_MODEL_632d56dcf0904b368d822266a500f1b4"
            ],
            "layout": "IPY_MODEL_519069c386944abab6d9efe68c689600"
          }
        },
        "77fc1b83f4fd48809536b19ef661608c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8635d141ecc14d31a6a6746ea8f88a1a",
            "placeholder": "​",
            "style": "IPY_MODEL_412fdc6a50584ad8a2e6a79244c134cf",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "dac2acfeba3b4f339fec5bcb8a2bd565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_568dcab198a946489a831421139d7086",
            "placeholder": "​",
            "style": "IPY_MODEL_f71ee43fa9f64b48898cfee34520f3cb",
            "value": ""
          }
        },
        "fab3f58ebd504358829c4f0b59bfc093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_52fb1ea697a7448ab6c644d1a210fcca",
            "style": "IPY_MODEL_0aa01f8aa4cc4f93ada68d7ed08b1c92",
            "value": true
          }
        },
        "986da26d1a264f919aebd4b7f9e745fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_e46a20ade6b849a6b55cdcdcd238fdab",
            "style": "IPY_MODEL_1cb44ef47afa49f3a4d37014b08c7be8",
            "tooltip": ""
          }
        },
        "53ac4a0f9c964ff2bfaef5b2e3e91410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49ec684a18814bfc96df792836df6501",
            "placeholder": "​",
            "style": "IPY_MODEL_67578e404f9c4b7095111b56f4d7c48b",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "519069c386944abab6d9efe68c689600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "8635d141ecc14d31a6a6746ea8f88a1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "412fdc6a50584ad8a2e6a79244c134cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "568dcab198a946489a831421139d7086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f71ee43fa9f64b48898cfee34520f3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52fb1ea697a7448ab6c644d1a210fcca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aa01f8aa4cc4f93ada68d7ed08b1c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e46a20ade6b849a6b55cdcdcd238fdab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cb44ef47afa49f3a4d37014b08c7be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "49ec684a18814bfc96df792836df6501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67578e404f9c4b7095111b56f4d7c48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e152cabde3e49898f0aa437f4572fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_934f9eb2595549878eedbfc64817702c",
            "placeholder": "​",
            "style": "IPY_MODEL_0a3a1a2d008c470b9cc9105826ece3df",
            "value": "Connecting..."
          }
        },
        "934f9eb2595549878eedbfc64817702c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a3a1a2d008c470b9cc9105826ece3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d0707c43c1943719665a8fa4402abea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3773cf421d664f958c66fa96c6a33dd5",
            "placeholder": "​",
            "style": "IPY_MODEL_16e3694f0cfe429792dd022b4af24891",
            "value": "Token is valid (permission: write)."
          }
        },
        "5bf07d4416f24b469c4370b919754f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cbe20cabf96437db68fa3eaf5725ae2",
            "placeholder": "​",
            "style": "IPY_MODEL_dd44dfe3202b405aa28493be525edcae",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "6190854c87b54fac8df857e08acfc8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a78a9ec98cb74d7c8b3fa41df7835687",
            "placeholder": "​",
            "style": "IPY_MODEL_4a6c6ebe04a84d1c8d593b47b0280e6f",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "632d56dcf0904b368d822266a500f1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803d19e416a2430185413125a44876e4",
            "placeholder": "​",
            "style": "IPY_MODEL_69ebe3c6aaa642efa2646ce28521b25b",
            "value": "Login successful"
          }
        },
        "3773cf421d664f958c66fa96c6a33dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16e3694f0cfe429792dd022b4af24891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cbe20cabf96437db68fa3eaf5725ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd44dfe3202b405aa28493be525edcae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a78a9ec98cb74d7c8b3fa41df7835687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a6c6ebe04a84d1c8d593b47b0280e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "803d19e416a2430185413125a44876e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69ebe3c6aaa642efa2646ce28521b25b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "090023f235604651a43896ac5451bc97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ebf9c48f7204d7f8eb77c8bd79c47b2",
              "IPY_MODEL_d7d79d8004164838b16d0a1253292faa",
              "IPY_MODEL_c78847b85bea407bac7a9469fda54bc4"
            ],
            "layout": "IPY_MODEL_43584e2ea0234e78bbbd350321ea6f8b"
          }
        },
        "4ebf9c48f7204d7f8eb77c8bd79c47b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85e736eeff2141a482d819b3da31b9b1",
            "placeholder": "​",
            "style": "IPY_MODEL_b214e45c1a034211b64acc31056944f0",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d7d79d8004164838b16d0a1253292faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9354831ec0b441228e2457a77119765c",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4aee667c7ddf40c28121c39529d6b894",
            "value": 8
          }
        },
        "c78847b85bea407bac7a9469fda54bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd0ed51f86fc401ba20833f164fd12a9",
            "placeholder": "​",
            "style": "IPY_MODEL_63aa86e0b6704738aa18f1e62fa56bab",
            "value": " 8/8 [01:13&lt;00:00,  8.04s/it]"
          }
        },
        "43584e2ea0234e78bbbd350321ea6f8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85e736eeff2141a482d819b3da31b9b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b214e45c1a034211b64acc31056944f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9354831ec0b441228e2457a77119765c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aee667c7ddf40c28121c39529d6b894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd0ed51f86fc401ba20833f164fd12a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63aa86e0b6704738aa18f1e62fa56bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af58df3abe4c4727b4c8ebe4e2d02cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_780cefa5afcb45ec9e34a26b66424084",
              "IPY_MODEL_ed1d62af41174f57b749ddcf1a09af8f",
              "IPY_MODEL_dd1dadf60c3d4b379f8cc3733f34c3e6"
            ],
            "layout": "IPY_MODEL_4a2125c2cd054a62ab4258e9e810b94c"
          }
        },
        "780cefa5afcb45ec9e34a26b66424084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82885845628244c380854f34a7da301e",
            "placeholder": "​",
            "style": "IPY_MODEL_6860adc8501b46c09ddcfb409e0edc01",
            "value": "adapter_config.json: 100%"
          }
        },
        "ed1d62af41174f57b749ddcf1a09af8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78401abe8c3f4b5abbe295f48c18816e",
            "max": 599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75b07bf4dfc84a549975630c4e964bb2",
            "value": 599
          }
        },
        "dd1dadf60c3d4b379f8cc3733f34c3e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccfd8f4b69f94a2e85c9ab2dcc479841",
            "placeholder": "​",
            "style": "IPY_MODEL_a12add763b5943bf82fdd7009549cd69",
            "value": " 599/599 [00:00&lt;00:00, 36.0kB/s]"
          }
        },
        "4a2125c2cd054a62ab4258e9e810b94c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82885845628244c380854f34a7da301e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6860adc8501b46c09ddcfb409e0edc01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78401abe8c3f4b5abbe295f48c18816e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b07bf4dfc84a549975630c4e964bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccfd8f4b69f94a2e85c9ab2dcc479841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a12add763b5943bf82fdd7009549cd69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc025a8916c3473d8fd839abf99c60cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e77f7fce481a45e4b7b257910329f1fe",
              "IPY_MODEL_ccdb8e0229514f97a9ca37589555836c",
              "IPY_MODEL_836b45b8858c4cbabd230cb454b02c70"
            ],
            "layout": "IPY_MODEL_e8c518a42393470d8fd7556c26576c69"
          }
        },
        "e77f7fce481a45e4b7b257910329f1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdeb36858f2495e9802f7b395e829bf",
            "placeholder": "​",
            "style": "IPY_MODEL_122eaf73c05f415da8df456f7655faea",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "ccdb8e0229514f97a9ca37589555836c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eaee89f775d462aae48858fb4670fb6",
            "max": 27280152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f040bc7c9384456854f4db6cbd17129",
            "value": 27280152
          }
        },
        "836b45b8858c4cbabd230cb454b02c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e8062d5592a4f7f9738d67f6208b938",
            "placeholder": "​",
            "style": "IPY_MODEL_3d05d02b73b44096a60ebd9c4f84fb6c",
            "value": " 27.3M/27.3M [00:00&lt;00:00, 47.0MB/s]"
          }
        },
        "e8c518a42393470d8fd7556c26576c69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bdeb36858f2495e9802f7b395e829bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122eaf73c05f415da8df456f7655faea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1eaee89f775d462aae48858fb4670fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f040bc7c9384456854f4db6cbd17129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e8062d5592a4f7f9738d67f6208b938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d05d02b73b44096a60ebd9c4f84fb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning Mistral 7b with AutoTrain"
      ],
      "metadata": {
        "id": "7oRhTab-3Isg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup Runtime\n",
        "For fine-tuning Llama, a GPU instance is essential. Follow the directions below:\n",
        "\n",
        "- Go to `Runtime` (located in the top menu bar).\n",
        "- Select `Change Runtime Type`.\n",
        "- Choose `T4 GPU` (or a comparable option)."
      ],
      "metadata": {
        "id": "yhDioAdc3ML5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Setup Environment"
      ],
      "metadata": {
        "id": "IJZt3QI73kWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas autotrain-advanced -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgvqeBz_3XvO",
        "outputId": "ae5f0962-b80b-402e-db77-9fd8455491b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.1/214.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.9/133.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwStofw4257S",
        "outputId": "cc442984-bdaa-46f5-be3f-256b3d1e51ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Installing latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest PyTorch\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest PyTorch\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!autotrain setup --update-torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Connect to HuggingFace for Model Upload\n",
        "\n",
        "### Logging to Hugging Face\n",
        "To make sure the model can be uploaded to be used for Inference, it's necessary to log in to the Hugging Face hub.\n",
        "\n",
        "### Getting a Hugging Face token\n",
        "Steps:\n",
        "\n",
        "1. Navigate to this URL: https://huggingface.co/settings/tokens\n",
        "2. Create a write `token` and copy it to your clipboard\n",
        "3. Run the code below and enter your `token`"
      ],
      "metadata": {
        "id": "H-zXccJMZEx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "6a6f140c23664eb9b41d3fdfaecd621c",
            "77fc1b83f4fd48809536b19ef661608c",
            "dac2acfeba3b4f339fec5bcb8a2bd565",
            "fab3f58ebd504358829c4f0b59bfc093",
            "986da26d1a264f919aebd4b7f9e745fe",
            "53ac4a0f9c964ff2bfaef5b2e3e91410",
            "519069c386944abab6d9efe68c689600",
            "8635d141ecc14d31a6a6746ea8f88a1a",
            "412fdc6a50584ad8a2e6a79244c134cf",
            "568dcab198a946489a831421139d7086",
            "f71ee43fa9f64b48898cfee34520f3cb",
            "52fb1ea697a7448ab6c644d1a210fcca",
            "0aa01f8aa4cc4f93ada68d7ed08b1c92",
            "e46a20ade6b849a6b55cdcdcd238fdab",
            "1cb44ef47afa49f3a4d37014b08c7be8",
            "49ec684a18814bfc96df792836df6501",
            "67578e404f9c4b7095111b56f4d7c48b",
            "0e152cabde3e49898f0aa437f4572fcf",
            "934f9eb2595549878eedbfc64817702c",
            "0a3a1a2d008c470b9cc9105826ece3df",
            "5d0707c43c1943719665a8fa4402abea",
            "5bf07d4416f24b469c4370b919754f4e",
            "6190854c87b54fac8df857e08acfc8c1",
            "632d56dcf0904b368d822266a500f1b4",
            "3773cf421d664f958c66fa96c6a33dd5",
            "16e3694f0cfe429792dd022b4af24891",
            "5cbe20cabf96437db68fa3eaf5725ae2",
            "dd44dfe3202b405aa28493be525edcae",
            "a78a9ec98cb74d7c8b3fa41df7835687",
            "4a6c6ebe04a84d1c8d593b47b0280e6f",
            "803d19e416a2430185413125a44876e4",
            "69ebe3c6aaa642efa2646ce28521b25b"
          ]
        },
        "id": "VzMLmLP86Ub-",
        "outputId": "c4f45263-2a73-4909-bb07-3f9680997fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a6f140c23664eb9b41d3fdfaecd621c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Upload your dataset\n",
        "\n",
        "Add your data set to the root directory in the Colab under the name train.csv. The AutoTrain command will look for your data there under that name.\n",
        "\n",
        "#### Don't have a data set and want to try finetuning on an example data set?\n",
        "If you don't have a dataset you can run these commands below to get an example data set and save it to train.csv"
      ],
      "metadata": {
        "id": "qY932JBNZmtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/joshbickett/finetune-llama-2.git\n",
        "%cd finetune-llama-2\n",
        "%mv train.csv ../train.csv\n",
        "%cd .."
      ],
      "metadata": {
        "id": "JxTn4r_YZdkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb8cb7e-03d9-40a2-8d15-b17cf245d5c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'finetune-llama-2'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 70 (delta 38), reused 48 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (70/70), 25.13 KiB | 12.57 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n",
            "/content/finetune-llama-2\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NUb-rkeoZzZ6",
        "outputId": "15992ecf-8532-4c8b-9ccd-981f4469ace1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Concept  \\\n",
              "0                 A cactus at a dance party   \n",
              "1                   A robot on a first date   \n",
              "2                A snail at a speed contest   \n",
              "3                A penguin at a beach party   \n",
              "4                     A cloud in a bad mood   \n",
              "..                                      ...   \n",
              "112      A donut feeling the hole emptiness   \n",
              "113     A pineapple with a prickly attitude   \n",
              "114  A calculator crunching life's problems   \n",
              "115             A kite reaching new heights   \n",
              "116            A teddy bear feeling stuffed   \n",
              "\n",
              "                              Funny Description Prompt  \\\n",
              "0    A cactus, wearing disco lights and surrounded ...   \n",
              "1    A robot, with a bouquet of USB cables, nervous...   \n",
              "2    A snail, with a mini rocket booster, confident...   \n",
              "3    A penguin, with sunscreen and a surfboard, try...   \n",
              "4    A cloud, grumbling and dropping mini lightning...   \n",
              "..                                                 ...   \n",
              "112  A donut, in existential bakery therapy, ponder...   \n",
              "113  A pineapple, in a prickly personality class, s...   \n",
              "114  A calculator, at a problem-solving workshop, c...   \n",
              "115  A kite, in an altitude adjustment session, unt...   \n",
              "116  A teddy bear, in a fluff mindfulness group, em...   \n",
              "\n",
              "                                                  text  \n",
              "0    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "1    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "2    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "3    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "4    ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "..                                                 ...  \n",
              "112  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "113  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "114  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "115  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "116  ###Human:\\nGenerate a midjourney prompt for A ...  \n",
              "\n",
              "[117 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc3118d4-a360-47f7-96fe-754b53de9f4f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Concept</th>\n",
              "      <th>Funny Description Prompt</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A cactus at a dance party</td>\n",
              "      <td>A cactus, wearing disco lights and surrounded ...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A robot on a first date</td>\n",
              "      <td>A robot, with a bouquet of USB cables, nervous...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A snail at a speed contest</td>\n",
              "      <td>A snail, with a mini rocket booster, confident...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A penguin at a beach party</td>\n",
              "      <td>A penguin, with sunscreen and a surfboard, try...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A cloud in a bad mood</td>\n",
              "      <td>A cloud, grumbling and dropping mini lightning...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>A donut feeling the hole emptiness</td>\n",
              "      <td>A donut, in existential bakery therapy, ponder...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>A pineapple with a prickly attitude</td>\n",
              "      <td>A pineapple, in a prickly personality class, s...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>A calculator crunching life's problems</td>\n",
              "      <td>A calculator, at a problem-solving workshop, c...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>A kite reaching new heights</td>\n",
              "      <td>A kite, in an altitude adjustment session, unt...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>A teddy bear feeling stuffed</td>\n",
              "      <td>A teddy bear, in a fluff mindfulness group, em...</td>\n",
              "      <td>###Human:\\nGenerate a midjourney prompt for A ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc3118d4-a360-47f7-96fe-754b53de9f4f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc3118d4-a360-47f7-96fe-754b53de9f4f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc3118d4-a360-47f7-96fe-754b53de9f4f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97a5a7fa-f96d-4a4e-8699-c63893ae44e3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97a5a7fa-f96d-4a4e-8699-c63893ae44e3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97a5a7fa-f96d-4a4e-8699-c63893ae44e3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5875b89f-a850-4cb9-889f-d11b367b35ab\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5875b89f-a850-4cb9-889f-d11b367b35ab button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'][15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3mr4WrwHZ0pv",
        "outputId": "2707144d-e173-4af7-8fe0-f4e63fb63726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'###Human:\\nGenerate a midjourney prompt for A book on a mystery adventure\\n\\n###Assistant:\\nA book, wearing detective glasses, flipping through its own pages, trying to solve the cliffhanger it was left on.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Overview of AutoTrain command\n",
        "\n",
        "#### Short overview of what the command flags do.\n",
        "\n",
        "- `!autotrain`: Command executed in environments like a Jupyter notebook to run shell commands directly. `autotrain` is an automatic training utility.\n",
        "\n",
        "- `llm`: A sub-command or argument specifying the type of task\n",
        "\n",
        "- `--train`: Initiates the training process.\n",
        "\n",
        "- `--project_name`: Sets the name of the project\n",
        "\n",
        "- `--model abhishek/llama-2-7b-hf-small-shards`: Specifies original model that is hosted on Hugging Face named \"llama-2-7b-hf-small-shards\" under the \"abhishek\".\n",
        "\n",
        "- `--data_path .`: The path to the dataset for training. The \".\" refers to the current directory. The `train.csv` file needs to be located in this directory.\n",
        "\n",
        "- `--use_int4`: Use of INT4 quantization to reduce model size and speed up inference times at the cost of some precision.\n",
        "\n",
        "- `--learning_rate 2e-4`: Sets the learning rate for training to 0.0002.\n",
        "\n",
        "- `--train_batch_size 12`: Sets the batch size for training to 12.\n",
        "\n",
        "- `--num_train_epochs 3`: The training process will iterate over the dataset 3 times.\n",
        "\n",
        "### Steps needed before running\n",
        "Go to the `!autotrain` code cell below and update it by following the steps below:\n",
        "\n",
        "1. After `--project_name` replace `*enter-a-project-name*` with the name that you'd like to call the project\n",
        "2. After `--repo_id` replace `*username*/*repository*`. Replace `*username*` with your Hugging Face username and `*repository*` with the repository name you'd like it to be created under. You don't need to create this repository before hand, it will automatically be created and uploaded once the training is completed.\n",
        "3. Confirm that `train.csv` is in the root directory in the Colab. The `--data_path .` flag will make it so that AutoTrain looks for your data there.\n",
        "4. Make sure to add the LoRA Target Modules to be trained `--target-modules q_proj, v_proj`\n",
        "5. Once you've made these changes you're all set, run the command below!"
      ],
      "metadata": {
        "id": "LEFbHxoPaDE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain llm --train --project-name mistral-7b-mj-finetuned --model filipealmeida/Mistral-7B-Instruct-v0.1-sharded --data-path . --use-peft --quantization int4 --lr 2e-4 --batch-size 12 --epochs 3 --trainer sft --target_modules q_proj,v_proj --push-to-hub --token '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' --repo-id Swapnilg915/mistral-7b-mj-finetuned"
      ],
      "metadata": {
        "id": "wFS31VJsZ-pa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a274e785-64a5-44ac-ac9f-a3c64aef9577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Running LLM\u001b[0m\n",
            "> \u001b[1mINFO    Params: Namespace(version=False, text_column='text', rejected_text_column='rejected', prompt_text_column='prompt', model_ref=None, warmup_ratio=0.1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.0, max_grad_norm=1.0, add_eos_token=False, block_size=-1, peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, mixed_precision=None, quantization='int4', model_max_length=1024, trainer='sft', target_modules='q_proj,v_proj', merge_adapter=False, use_flash_attention_2=False, dpo_beta=0.1, apply_chat_template=False, padding=None, train=True, deploy=False, inference=False, username=None, backend='local-cli', token='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', repo_id='Swapnilg915/mistral-7b-mj-finetuned', push_to_hub=True, model='filipealmeida/Mistral-7B-Instruct-v0.1-sharded', project_name='mistral-7b-mj-finetuned', seed=42, epochs=3, gradient_accumulation=1, disable_gradient_checkpointing=False, lr=0.0002, log='none', data_path='.', train_split='train', valid_split=None, batch_size=12, func=<function run_llm_command_factory at 0x7ee1cbe15cf0>)\u001b[0m\n",
            "> \u001b[1mINFO    Dataset: mistral-7b-mj-finetuned (lm_training)\n",
            "Train data: ['./train.csv']\n",
            "Valid data: []\n",
            "Column mapping: {'text': 'text', 'rejected_text': 'rejected', 'prompt': 'prompt'}\n",
            "\u001b[0m\n",
            "\rSaving the dataset (0/1 shards):   0% 0/117 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 117/117 [00:00<00:00, 40263.67 examples/s]\rSaving the dataset (1/1 shards): 100% 117/117 [00:00<00:00, 38216.15 examples/s]\n",
            "\rSaving the dataset (0/1 shards):   0% 0/117 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 117/117 [00:00<00:00, 48606.73 examples/s]\rSaving the dataset (1/1 shards): 100% 117/117 [00:00<00:00, 45602.97 examples/s]\n",
            "> \u001b[1mINFO    Starting local training...\u001b[0m\n",
            "> \u001b[1mINFO    {\"model\":\"filipealmeida/Mistral-7B-Instruct-v0.1-sharded\",\"project_name\":\"mistral-7b-mj-finetuned\",\"data_path\":\"mistral-7b-mj-finetuned/autotrain-data\",\"train_split\":\"train\",\"valid_split\":null,\"add_eos_token\":false,\"block_size\":-1,\"model_max_length\":1024,\"padding\":null,\"trainer\":\"sft\",\"use_flash_attention_2\":false,\"log\":\"none\",\"disable_gradient_checkpointing\":false,\"logging_steps\":-1,\"evaluation_strategy\":\"epoch\",\"save_total_limit\":1,\"save_strategy\":\"epoch\",\"auto_find_batch_size\":false,\"mixed_precision\":null,\"lr\":0.0002,\"epochs\":3,\"batch_size\":12,\"warmup_ratio\":0.1,\"gradient_accumulation\":1,\"optimizer\":\"adamw_torch\",\"scheduler\":\"linear\",\"weight_decay\":0.0,\"max_grad_norm\":1.0,\"seed\":42,\"apply_chat_template\":false,\"quantization\":\"int4\",\"target_modules\":\"q_proj,v_proj\",\"merge_adapter\":false,\"peft\":true,\"lora_r\":16,\"lora_alpha\":32,\"lora_dropout\":0.05,\"model_ref\":null,\"dpo_beta\":0.1,\"prompt_text_column\":\"autotrain_prompt\",\"text_column\":\"autotrain_text\",\"rejected_text_column\":\"autotrain_rejected_text\",\"push_to_hub\":true,\"repo_id\":\"Swapnilg915/mistral-7b-mj-finetuned\",\"username\":null,\"token\":\"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\"}\u001b[0m\n",
            "> \u001b[1mINFO    ['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'no', '-m', 'autotrain.trainers.clm', '--training_config', 'mistral-7b-mj-finetuned/training_params.json']\u001b[0m\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
            "  warnings.warn(\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 14:09:53\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mloading dataset from disk\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 14:09:53\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mTrain data: Dataset({\n",
            "    features: ['Concept', 'Funny Description Prompt', 'autotrain_text'],\n",
            "    num_rows: 117\n",
            "})\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 14:09:53\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mValid data: None\u001b[0m\n",
            "tokenizer_config.json: 100% 1.47k/1.47k [00:00<00:00, 8.41MB/s]\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 15.5MB/s]\n",
            "tokenizer.json: 100% 1.80M/1.80M [00:00<00:00, 8.74MB/s]\n",
            "special_tokens_map.json: 100% 72.0/72.0 [00:00<00:00, 447kB/s]\n",
            "config.json: 100% 665/665 [00:00<00:00, 4.23MB/s]\n",
            "pytorch_model.bin.index.json: 100% 23.9k/23.9k [00:00<00:00, 83.2MB/s]\n",
            "Downloading shards:   0% 0/8 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00008.bin:   0% 0.00/1.89G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:   2% 31.5M/1.89G [00:00<00:07, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:   3% 62.9M/1.89G [00:00<00:06, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:   5% 94.4M/1.89G [00:00<00:06, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:   7% 126M/1.89G [00:00<00:06, 290MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00008.bin:   8% 157M/1.89G [00:00<00:06, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  10% 189M/1.89G [00:00<00:06, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  12% 220M/1.89G [00:00<00:06, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  13% 252M/1.89G [00:00<00:06, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  15% 283M/1.89G [00:02<00:27, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  16% 304M/1.89G [00:02<00:22, 70.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  17% 325M/1.89G [00:02<00:19, 81.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  18% 346M/1.89G [00:02<00:19, 81.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  19% 367M/1.89G [00:02<00:15, 96.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  21% 398M/1.89G [00:03<00:12, 124MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  23% 430M/1.89G [00:03<00:10, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  24% 461M/1.89G [00:03<00:09, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  26% 493M/1.89G [00:03<00:08, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  28% 524M/1.89G [00:03<00:07, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  29% 556M/1.89G [00:03<00:06, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  31% 587M/1.89G [00:03<00:05, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  33% 619M/1.89G [00:04<00:06, 208MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  34% 650M/1.89G [00:04<00:05, 215MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  36% 682M/1.89G [00:04<00:05, 212MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  38% 713M/1.89G [00:04<00:05, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  39% 744M/1.89G [00:04<00:04, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  41% 776M/1.89G [00:04<00:04, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  43% 807M/1.89G [00:04<00:05, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  44% 839M/1.89G [00:05<00:05, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  46% 860M/1.89G [00:05<00:05, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  47% 881M/1.89G [00:05<00:05, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  48% 902M/1.89G [00:05<00:05, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  49% 923M/1.89G [00:05<00:05, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  50% 944M/1.89G [00:05<00:04, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  51% 965M/1.89G [00:05<00:04, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  53% 996M/1.89G [00:05<00:04, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  54% 1.03G/1.89G [00:06<00:03, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  56% 1.06G/1.89G [00:06<00:03, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  58% 1.09G/1.89G [00:06<00:03, 219MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  59% 1.12G/1.89G [00:06<00:03, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  61% 1.15G/1.89G [00:06<00:03, 224MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  63% 1.18G/1.89G [00:06<00:03, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  64% 1.22G/1.89G [00:07<00:06, 109MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  65% 1.24G/1.89G [00:07<00:05, 114MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  67% 1.26G/1.89G [00:07<00:06, 104MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  68% 1.29G/1.89G [00:07<00:04, 131MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  70% 1.32G/1.89G [00:08<00:03, 150MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  72% 1.35G/1.89G [00:08<00:03, 175MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  73% 1.38G/1.89G [00:08<00:02, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  75% 1.42G/1.89G [00:08<00:02, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  77% 1.45G/1.89G [00:08<00:02, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  78% 1.48G/1.89G [00:08<00:01, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  80% 1.51G/1.89G [00:08<00:01, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  82% 1.54G/1.89G [00:09<00:01, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  83% 1.57G/1.89G [00:09<00:01, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  85% 1.60G/1.89G [00:09<00:01, 239MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  87% 1.64G/1.89G [00:09<00:01, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  88% 1.67G/1.89G [00:09<00:00, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  90% 1.70G/1.89G [00:09<00:00, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  92% 1.73G/1.89G [00:09<00:00, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  93% 1.76G/1.89G [00:09<00:00, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  95% 1.79G/1.89G [00:10<00:00, 242MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  97% 1.82G/1.89G [00:10<00:00, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin:  98% 1.86G/1.89G [00:10<00:00, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00008.bin: 100% 1.89G/1.89G [00:10<00:00, 180MB/s]\n",
            "Downloading shards:  12% 1/8 [00:10<01:14, 10.59s/it]\n",
            "pytorch_model-00002-of-00008.bin:   0% 0.00/1.95G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:   2% 31.5M/1.95G [00:00<00:07, 268MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:   3% 62.9M/1.95G [00:00<00:06, 285MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:   5% 94.4M/1.95G [00:00<00:06, 290MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:   6% 126M/1.95G [00:00<00:06, 285MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00008.bin:   8% 157M/1.95G [00:00<00:06, 261MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  10% 189M/1.95G [00:00<00:07, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  11% 220M/1.95G [00:00<00:06, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  13% 252M/1.95G [00:01<00:20, 82.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  15% 283M/1.95G [00:01<00:15, 106MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  16% 315M/1.95G [00:02<00:15, 105MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  17% 336M/1.95G [00:02<00:14, 111MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  18% 357M/1.95G [00:02<00:12, 125MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  20% 388M/1.95G [00:02<00:10, 150MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  21% 409M/1.95G [00:02<00:09, 157MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  22% 430M/1.95G [00:02<00:09, 152MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  23% 451M/1.95G [00:02<00:09, 164MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  25% 482M/1.95G [00:03<00:08, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  26% 503M/1.95G [00:04<00:25, 56.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  27% 535M/1.95G [00:04<00:18, 78.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  29% 566M/1.95G [00:04<00:13, 99.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  31% 598M/1.95G [00:04<00:10, 125MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  32% 629M/1.95G [00:04<00:08, 148MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  34% 661M/1.95G [00:04<00:07, 169MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  36% 692M/1.95G [00:05<00:07, 170MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  37% 724M/1.95G [00:05<00:06, 187MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  39% 755M/1.95G [00:06<00:24, 48.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  40% 776M/1.95G [00:07<00:20, 58.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  41% 797M/1.95G [00:07<00:16, 70.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  42% 818M/1.95G [00:07<00:13, 84.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  43% 839M/1.95G [00:07<00:11, 99.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  45% 870M/1.95G [00:07<00:08, 130MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  46% 902M/1.95G [00:07<00:06, 160MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  48% 933M/1.95G [00:07<00:05, 188MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  50% 965M/1.95G [00:07<00:04, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  51% 996M/1.95G [00:07<00:04, 200MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  53% 1.03G/1.95G [00:08<00:05, 161MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  54% 1.06G/1.95G [00:08<00:04, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  56% 1.09G/1.95G [00:11<00:32, 26.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  57% 1.11G/1.95G [00:12<00:26, 32.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  58% 1.13G/1.95G [00:12<00:21, 38.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  60% 1.16G/1.95G [00:12<00:14, 54.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  61% 1.20G/1.95G [00:12<00:10, 72.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  63% 1.23G/1.95G [00:12<00:08, 87.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  65% 1.26G/1.95G [00:12<00:06, 109MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  66% 1.29G/1.95G [00:12<00:04, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  68% 1.32G/1.95G [00:13<00:04, 155MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  70% 1.35G/1.95G [00:13<00:03, 175MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  71% 1.38G/1.95G [00:13<00:02, 193MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  73% 1.42G/1.95G [00:13<00:02, 208MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  74% 1.45G/1.95G [00:13<00:02, 220MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  76% 1.48G/1.95G [00:13<00:02, 226MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  78% 1.51G/1.95G [00:13<00:01, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  79% 1.54G/1.95G [00:13<00:01, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  81% 1.57G/1.95G [00:14<00:01, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  82% 1.60G/1.95G [00:14<00:01, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  84% 1.64G/1.95G [00:14<00:01, 247MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  86% 1.67G/1.95G [00:14<00:01, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  87% 1.70G/1.95G [00:14<00:01, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  89% 1.73G/1.95G [00:14<00:00, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  91% 1.76G/1.95G [00:14<00:00, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  92% 1.79G/1.95G [00:14<00:00, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  94% 1.82G/1.95G [00:15<00:00, 169MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  95% 1.86G/1.95G [00:15<00:00, 192MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  97% 1.89G/1.95G [00:15<00:00, 214MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin:  99% 1.92G/1.95G [00:15<00:00, 229MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00008.bin: 100% 1.95G/1.95G [00:15<00:00, 123MB/s]\n",
            "Downloading shards:  25% 2/8 [00:26<01:22, 13.71s/it]\n",
            "pytorch_model-00003-of-00008.bin:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:   2% 31.5M/1.98G [00:00<00:07, 260MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:   3% 62.9M/1.98G [00:00<00:07, 248MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:   5% 94.4M/1.98G [00:00<00:22, 83.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:   6% 115M/1.98G [00:01<00:19, 94.0MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00008.bin:   7% 136M/1.98G [00:01<00:19, 95.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:   8% 157M/1.98G [00:01<00:15, 114MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  10% 189M/1.98G [00:01<00:13, 138MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  11% 220M/1.98G [00:01<00:11, 157MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  12% 241M/1.98G [00:01<00:11, 154MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  13% 262M/1.98G [00:01<00:10, 159MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  15% 294M/1.98G [00:02<00:09, 170MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  16% 325M/1.98G [00:02<00:08, 187MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  18% 357M/1.98G [00:02<00:07, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  20% 388M/1.98G [00:02<00:07, 212MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  21% 419M/1.98G [00:02<00:08, 193MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  22% 440M/1.98G [00:02<00:08, 189MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  23% 461M/1.98G [00:02<00:08, 186MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  24% 482M/1.98G [00:03<00:07, 187MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  25% 503M/1.98G [00:03<00:07, 190MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  26% 524M/1.98G [00:05<00:59, 24.6MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  28% 545M/1.98G [00:06<00:43, 32.7MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  29% 566M/1.98G [00:06<00:36, 39.0MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  30% 598M/1.98G [00:06<00:23, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  32% 629M/1.98G [00:06<00:16, 80.1MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  33% 661M/1.98G [00:06<00:12, 106MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  35% 692M/1.98G [00:06<00:11, 113MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  37% 724M/1.98G [00:07<00:09, 136MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  38% 755M/1.98G [00:07<00:07, 159MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  40% 786M/1.98G [00:07<00:06, 179MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  41% 818M/1.98G [00:07<00:06, 181MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  43% 849M/1.98G [00:07<00:05, 205MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  44% 881M/1.98G [00:07<00:05, 212MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  46% 912M/1.98G [00:07<00:04, 215MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  48% 944M/1.98G [00:07<00:04, 223MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  49% 975M/1.98G [00:10<00:31, 31.7MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  50% 996M/1.98G [00:11<00:26, 36.5MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  52% 1.03G/1.98G [00:11<00:18, 50.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  53% 1.06G/1.98G [00:11<00:13, 66.7MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  55% 1.09G/1.98G [00:11<00:10, 87.8MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  57% 1.12G/1.98G [00:11<00:08, 100MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  58% 1.15G/1.98G [00:11<00:06, 121MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  60% 1.18G/1.98G [00:12<00:05, 141MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  61% 1.22G/1.98G [00:12<00:04, 162MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  63% 1.25G/1.98G [00:12<00:03, 184MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  65% 1.28G/1.98G [00:12<00:04, 146MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  66% 1.31G/1.98G [00:12<00:03, 172MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  68% 1.34G/1.98G [00:12<00:03, 198MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  69% 1.37G/1.98G [00:12<00:02, 206MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  71% 1.41G/1.98G [00:13<00:02, 207MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  73% 1.44G/1.98G [00:13<00:02, 213MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  74% 1.47G/1.98G [00:13<00:02, 205MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  76% 1.50G/1.98G [00:16<00:14, 34.2MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  77% 1.52G/1.98G [00:16<00:10, 41.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  78% 1.55G/1.98G [00:16<00:07, 56.9MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  80% 1.58G/1.98G [00:16<00:05, 76.3MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  82% 1.61G/1.98G [00:16<00:03, 98.4MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  83% 1.65G/1.98G [00:16<00:03, 110MB/s] \u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  85% 1.68G/1.98G [00:16<00:02, 132MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  86% 1.71G/1.98G [00:17<00:01, 152MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  88% 1.74G/1.98G [00:17<00:01, 171MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  90% 1.77G/1.98G [00:17<00:01, 190MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  91% 1.80G/1.98G [00:17<00:00, 204MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  93% 1.84G/1.98G [00:17<00:00, 221MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  94% 1.87G/1.98G [00:17<00:00, 228MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  96% 1.90G/1.98G [00:17<00:00, 236MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin:  97% 1.93G/1.98G [00:17<00:00, 239MB/s]\u001b[A\n",
            "pytorch_model-00003-of-00008.bin: 100% 1.98G/1.98G [00:18<00:00, 109MB/s]\n",
            "Downloading shards:  38% 3/8 [00:44<01:18, 15.80s/it]\n",
            "pytorch_model-00004-of-00008.bin:   0% 0.00/1.95G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:   2% 31.5M/1.95G [00:00<00:06, 286MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:   3% 62.9M/1.95G [00:00<00:06, 290MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:   5% 94.4M/1.95G [00:00<00:06, 281MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:   6% 126M/1.95G [00:00<00:07, 228MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00008.bin:   8% 157M/1.95G [00:00<00:07, 235MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  10% 189M/1.95G [00:00<00:07, 229MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  11% 220M/1.95G [00:02<00:39, 43.4MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  12% 241M/1.95G [00:02<00:32, 52.8MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  13% 262M/1.95G [00:03<00:27, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  15% 283M/1.95G [00:03<00:22, 74.1MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  16% 315M/1.95G [00:03<00:16, 99.6MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  18% 346M/1.95G [00:03<00:12, 125MB/s] \u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  19% 367M/1.95G [00:03<00:11, 137MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  20% 388M/1.95G [00:03<00:11, 141MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  22% 419M/1.95G [00:03<00:09, 164MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  23% 451M/1.95G [00:03<00:08, 184MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  25% 482M/1.95G [00:04<00:07, 199MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  26% 514M/1.95G [00:04<00:06, 216MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  28% 545M/1.95G [00:04<00:06, 227MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  30% 577M/1.95G [00:04<00:05, 237MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  31% 608M/1.95G [00:04<00:05, 238MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  33% 640M/1.95G [00:04<00:05, 240MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  34% 671M/1.95G [00:04<00:05, 242MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  36% 703M/1.95G [00:04<00:04, 249MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  38% 734M/1.95G [00:05<00:04, 252MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  39% 765M/1.95G [00:05<00:04, 248MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  41% 797M/1.95G [00:05<00:04, 244MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  43% 828M/1.95G [00:05<00:04, 246MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  44% 860M/1.95G [00:05<00:04, 241MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  46% 891M/1.95G [00:05<00:04, 248MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  47% 923M/1.95G [00:05<00:04, 249MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  49% 954M/1.95G [00:05<00:03, 250MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  51% 986M/1.95G [00:06<00:03, 257MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  52% 1.02G/1.95G [00:06<00:03, 259MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  54% 1.05G/1.95G [00:06<00:03, 258MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  55% 1.08G/1.95G [00:06<00:03, 264MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  57% 1.11G/1.95G [00:06<00:03, 250MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  59% 1.14G/1.95G [00:06<00:03, 242MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  60% 1.17G/1.95G [00:06<00:03, 232MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  62% 1.21G/1.95G [00:06<00:03, 241MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  64% 1.24G/1.95G [00:07<00:03, 235MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  65% 1.27G/1.95G [00:07<00:03, 221MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  67% 1.30G/1.95G [00:07<00:02, 233MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  68% 1.33G/1.95G [00:07<00:02, 219MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  70% 1.36G/1.95G [00:07<00:02, 210MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  72% 1.39G/1.95G [00:07<00:02, 210MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  73% 1.43G/1.95G [00:07<00:02, 216MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  75% 1.46G/1.95G [00:08<00:02, 212MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  77% 1.49G/1.95G [00:08<00:02, 226MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  78% 1.52G/1.95G [00:08<00:01, 216MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  80% 1.55G/1.95G [00:08<00:01, 201MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  81% 1.57G/1.95G [00:08<00:01, 201MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  82% 1.59G/1.95G [00:08<00:01, 200MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  83% 1.61G/1.95G [00:08<00:01, 201MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  85% 1.65G/1.95G [00:09<00:01, 207MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  86% 1.68G/1.95G [00:09<00:01, 215MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  88% 1.71G/1.95G [00:09<00:01, 224MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  89% 1.74G/1.95G [00:09<00:00, 233MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  91% 1.77G/1.95G [00:09<00:00, 242MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  93% 1.80G/1.95G [00:09<00:00, 250MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  94% 1.84G/1.95G [00:09<00:00, 237MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  96% 1.87G/1.95G [00:09<00:00, 246MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin:  98% 1.90G/1.95G [00:10<00:00, 226MB/s]\u001b[A\n",
            "pytorch_model-00004-of-00008.bin: 100% 1.95G/1.95G [00:10<00:00, 188MB/s]\n",
            "Downloading shards:  50% 4/8 [00:55<00:54, 13.69s/it]\n",
            "pytorch_model-00005-of-00008.bin:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:   2% 31.5M/1.98G [00:00<00:08, 221MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:   3% 62.9M/1.98G [00:00<00:09, 204MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:   5% 94.4M/1.98G [00:00<00:08, 216MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:   6% 126M/1.98G [00:02<00:44, 41.8MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:   7% 147M/1.98G [00:02<00:34, 52.8MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:   8% 168M/1.98G [00:02<00:29, 60.4MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  10% 199M/1.98G [00:02<00:21, 84.6MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  12% 231M/1.98G [00:02<00:16, 108MB/s] \u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  13% 262M/1.98G [00:02<00:12, 133MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  14% 283M/1.98G [00:02<00:11, 146MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  15% 304M/1.98G [00:03<00:10, 156MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  16% 325M/1.98G [00:03<00:09, 167MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  18% 357M/1.98G [00:03<00:08, 188MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  20% 388M/1.98G [00:03<00:07, 206MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  21% 419M/1.98G [00:03<00:07, 214MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  23% 451M/1.98G [00:03<00:07, 218MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  24% 482M/1.98G [00:03<00:06, 229MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  26% 514M/1.98G [00:03<00:06, 240MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  28% 545M/1.98G [00:04<00:05, 242MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  29% 577M/1.98G [00:04<00:05, 245MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  31% 608M/1.98G [00:04<00:05, 247MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  32% 640M/1.98G [00:04<00:05, 241MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  34% 671M/1.98G [00:04<00:05, 249MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  35% 703M/1.98G [00:04<00:05, 250MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  37% 734M/1.98G [00:04<00:04, 254MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  39% 765M/1.98G [00:04<00:04, 255MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  40% 797M/1.98G [00:05<00:04, 247MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  42% 828M/1.98G [00:05<00:04, 254MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  43% 860M/1.98G [00:05<00:04, 248MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  45% 891M/1.98G [00:05<00:04, 242MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  47% 923M/1.98G [00:05<00:04, 246MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  48% 954M/1.98G [00:05<00:04, 250MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  50% 986M/1.98G [00:05<00:03, 251MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  51% 1.02G/1.98G [00:05<00:03, 252MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  53% 1.05G/1.98G [00:06<00:03, 257MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  55% 1.08G/1.98G [00:06<00:03, 256MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  56% 1.11G/1.98G [00:06<00:03, 257MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  58% 1.14G/1.98G [00:06<00:03, 251MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  59% 1.17G/1.98G [00:06<00:03, 250MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  61% 1.21G/1.98G [00:06<00:03, 254MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  62% 1.24G/1.98G [00:06<00:02, 253MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  64% 1.27G/1.98G [00:06<00:02, 252MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  66% 1.30G/1.98G [00:07<00:02, 250MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  67% 1.33G/1.98G [00:07<00:02, 251MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  69% 1.36G/1.98G [00:07<00:02, 260MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  70% 1.39G/1.98G [00:07<00:02, 264MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  72% 1.43G/1.98G [00:07<00:02, 268MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  74% 1.46G/1.98G [00:07<00:01, 273MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  75% 1.49G/1.98G [00:07<00:01, 247MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  77% 1.52G/1.98G [00:07<00:01, 240MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  78% 1.55G/1.98G [00:08<00:01, 244MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  80% 1.58G/1.98G [00:08<00:01, 250MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  82% 1.61G/1.98G [00:08<00:01, 249MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  83% 1.65G/1.98G [00:08<00:01, 246MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  85% 1.68G/1.98G [00:08<00:01, 238MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  86% 1.71G/1.98G [00:08<00:01, 245MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  88% 1.74G/1.98G [00:08<00:00, 239MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  90% 1.77G/1.98G [00:08<00:00, 232MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  91% 1.80G/1.98G [00:09<00:00, 223MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  93% 1.84G/1.98G [00:09<00:00, 222MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  94% 1.87G/1.98G [00:09<00:00, 230MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  96% 1.90G/1.98G [00:09<00:00, 236MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin:  97% 1.93G/1.98G [00:09<00:00, 232MB/s]\u001b[A\n",
            "pytorch_model-00005-of-00008.bin: 100% 1.98G/1.98G [00:09<00:00, 198MB/s]\n",
            "Downloading shards:  62% 5/8 [01:05<00:37, 12.41s/it]\n",
            "pytorch_model-00006-of-00008.bin:   0% 0.00/1.95G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:   2% 31.5M/1.95G [00:00<00:07, 254MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:   3% 62.9M/1.95G [00:00<00:07, 252MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:   5% 94.4M/1.95G [00:00<00:07, 251MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:   6% 126M/1.95G [00:00<00:07, 245MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00008.bin:   8% 157M/1.95G [00:00<00:08, 216MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  10% 189M/1.95G [00:00<00:08, 203MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  11% 210M/1.95G [00:00<00:08, 203MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  12% 231M/1.95G [00:01<00:08, 203MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  13% 252M/1.95G [00:02<00:27, 62.0MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  15% 283M/1.95G [00:02<00:23, 71.0MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  16% 315M/1.95G [00:02<00:17, 96.0MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  18% 346M/1.95G [00:02<00:13, 121MB/s] \u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  19% 377M/1.95G [00:02<00:10, 144MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  21% 409M/1.95G [00:02<00:09, 168MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  23% 440M/1.95G [00:03<00:08, 172MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  24% 472M/1.95G [00:03<00:08, 179MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  26% 503M/1.95G [00:03<00:07, 196MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  27% 535M/1.95G [00:03<00:06, 210MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  29% 566M/1.95G [00:03<00:06, 216MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  31% 598M/1.95G [00:03<00:06, 223MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  32% 629M/1.95G [00:03<00:05, 232MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  34% 661M/1.95G [00:03<00:05, 233MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  36% 692M/1.95G [00:04<00:05, 236MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  37% 724M/1.95G [00:04<00:04, 245MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  39% 755M/1.95G [00:04<00:04, 239MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  40% 786M/1.95G [00:04<00:04, 243MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  42% 818M/1.95G [00:04<00:04, 245MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  44% 849M/1.95G [00:04<00:04, 252MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  45% 881M/1.95G [00:04<00:04, 247MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  47% 912M/1.95G [00:04<00:04, 248MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  48% 944M/1.95G [00:05<00:04, 249MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  50% 975M/1.95G [00:05<00:03, 250MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  52% 1.01G/1.95G [00:05<00:03, 249MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  53% 1.04G/1.95G [00:05<00:03, 253MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  55% 1.07G/1.95G [00:05<00:03, 250MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  57% 1.10G/1.95G [00:05<00:03, 250MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  58% 1.13G/1.95G [00:05<00:03, 250MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  60% 1.16G/1.95G [00:05<00:03, 247MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  61% 1.20G/1.95G [00:06<00:03, 246MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  63% 1.23G/1.95G [00:06<00:02, 252MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  65% 1.26G/1.95G [00:06<00:02, 255MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  66% 1.29G/1.95G [00:06<00:02, 255MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  68% 1.32G/1.95G [00:06<00:02, 255MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  70% 1.35G/1.95G [00:06<00:02, 244MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  71% 1.38G/1.95G [00:06<00:02, 254MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  73% 1.42G/1.95G [00:06<00:02, 256MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  74% 1.45G/1.95G [00:07<00:01, 251MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  76% 1.48G/1.95G [00:07<00:01, 253MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  78% 1.51G/1.95G [00:07<00:01, 255MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  79% 1.54G/1.95G [00:07<00:01, 256MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  81% 1.57G/1.95G [00:07<00:01, 264MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  82% 1.60G/1.95G [00:07<00:01, 270MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  84% 1.64G/1.95G [00:07<00:01, 277MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  86% 1.67G/1.95G [00:07<00:01, 263MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  87% 1.70G/1.95G [00:08<00:00, 251MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  89% 1.73G/1.95G [00:08<00:00, 243MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  91% 1.76G/1.95G [00:08<00:00, 247MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  92% 1.79G/1.95G [00:08<00:00, 252MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  94% 1.82G/1.95G [00:08<00:00, 249MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  95% 1.86G/1.95G [00:08<00:00, 244MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  97% 1.89G/1.95G [00:08<00:00, 248MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin:  99% 1.92G/1.95G [00:08<00:00, 245MB/s]\u001b[A\n",
            "pytorch_model-00006-of-00008.bin: 100% 1.95G/1.95G [00:09<00:00, 214MB/s]\n",
            "Downloading shards:  75% 6/8 [01:14<00:22, 11.32s/it]\n",
            "pytorch_model-00007-of-00008.bin:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:   2% 31.5M/1.98G [00:00<00:06, 286MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:   3% 62.9M/1.98G [00:00<00:06, 287MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:   5% 94.4M/1.98G [00:00<00:06, 288MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:   6% 126M/1.98G [00:00<00:07, 260MB/s] \u001b[A\n",
            "pytorch_model-00007-of-00008.bin:   8% 157M/1.98G [00:00<00:07, 245MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  10% 189M/1.98G [00:00<00:07, 246MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  11% 220M/1.98G [00:00<00:07, 240MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  13% 252M/1.98G [00:02<00:41, 41.2MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  14% 273M/1.98G [00:03<00:34, 50.2MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  15% 294M/1.98G [00:03<00:31, 53.2MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  16% 325M/1.98G [00:03<00:22, 72.8MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  18% 357M/1.98G [00:03<00:17, 95.3MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  20% 388M/1.98G [00:03<00:13, 121MB/s] \u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  21% 419M/1.98G [00:03<00:10, 143MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  23% 451M/1.98G [00:04<00:09, 153MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  24% 482M/1.98G [00:04<00:08, 174MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  26% 514M/1.98G [00:04<00:07, 189MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  28% 545M/1.98G [00:04<00:06, 205MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  29% 577M/1.98G [00:04<00:06, 217MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  31% 608M/1.98G [00:04<00:06, 223MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  32% 640M/1.98G [00:04<00:05, 227MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  34% 671M/1.98G [00:04<00:05, 238MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  35% 703M/1.98G [00:05<00:05, 238MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  37% 734M/1.98G [00:05<00:05, 243MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  39% 765M/1.98G [00:05<00:05, 242MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  40% 797M/1.98G [00:05<00:04, 250MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  42% 828M/1.98G [00:05<00:04, 244MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  43% 860M/1.98G [00:05<00:04, 243MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  45% 891M/1.98G [00:05<00:04, 247MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  47% 923M/1.98G [00:06<00:04, 253MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  48% 954M/1.98G [00:06<00:04, 250MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  50% 986M/1.98G [00:06<00:03, 250MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  51% 1.02G/1.98G [00:06<00:03, 248MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  53% 1.05G/1.98G [00:06<00:03, 251MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  55% 1.08G/1.98G [00:06<00:03, 249MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  56% 1.11G/1.98G [00:06<00:03, 250MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  58% 1.14G/1.98G [00:06<00:03, 251MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  59% 1.17G/1.98G [00:07<00:03, 250MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  61% 1.21G/1.98G [00:07<00:03, 255MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  62% 1.24G/1.98G [00:07<00:02, 250MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  64% 1.27G/1.98G [00:07<00:02, 251MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  66% 1.30G/1.98G [00:07<00:02, 245MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  67% 1.33G/1.98G [00:07<00:02, 255MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  69% 1.36G/1.98G [00:07<00:02, 252MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  70% 1.39G/1.98G [00:07<00:02, 247MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  72% 1.43G/1.98G [00:08<00:02, 250MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  74% 1.46G/1.98G [00:08<00:02, 254MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  75% 1.49G/1.98G [00:08<00:01, 260MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  77% 1.52G/1.98G [00:08<00:01, 267MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  78% 1.55G/1.98G [00:08<00:01, 271MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  80% 1.58G/1.98G [00:08<00:01, 254MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  82% 1.61G/1.98G [00:08<00:01, 237MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  83% 1.65G/1.98G [00:08<00:01, 244MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  85% 1.68G/1.98G [00:09<00:01, 242MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  86% 1.71G/1.98G [00:09<00:01, 248MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  88% 1.74G/1.98G [00:09<00:00, 247MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  90% 1.77G/1.98G [00:09<00:00, 248MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  91% 1.80G/1.98G [00:09<00:00, 250MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  93% 1.84G/1.98G [00:09<00:00, 253MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  94% 1.87G/1.98G [00:09<00:00, 254MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  96% 1.90G/1.98G [00:09<00:00, 254MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin:  97% 1.93G/1.98G [00:10<00:00, 252MB/s]\u001b[A\n",
            "pytorch_model-00007-of-00008.bin: 100% 1.98G/1.98G [00:10<00:00, 193MB/s]\n",
            "Downloading shards:  88% 7/8 [01:24<00:11, 11.00s/it]\n",
            "pytorch_model-00008-of-00008.bin:   0% 0.00/816M [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:   4% 31.5M/816M [00:00<00:02, 284MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:   8% 62.9M/816M [00:00<00:02, 289MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  12% 94.4M/816M [00:00<00:02, 282MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  15% 126M/816M [00:00<00:02, 250MB/s] \u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  19% 157M/816M [00:00<00:02, 238MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  23% 189M/816M [00:00<00:02, 230MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  27% 220M/816M [00:00<00:02, 234MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  31% 252M/816M [00:01<00:02, 232MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  35% 283M/816M [00:01<00:02, 233MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  39% 315M/816M [00:01<00:02, 238MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  42% 346M/816M [00:01<00:01, 238MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  46% 377M/816M [00:01<00:01, 238MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  50% 409M/816M [00:01<00:01, 240MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  54% 440M/816M [00:01<00:01, 246MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  58% 472M/816M [00:01<00:01, 244MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  62% 503M/816M [00:02<00:01, 248MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  66% 535M/816M [00:02<00:01, 249MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  69% 566M/816M [00:02<00:00, 250MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  73% 598M/816M [00:02<00:00, 248MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  77% 629M/816M [00:02<00:00, 245MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  81% 661M/816M [00:02<00:00, 253MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  85% 692M/816M [00:02<00:00, 237MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  89% 724M/816M [00:02<00:00, 238MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  93% 755M/816M [00:03<00:00, 229MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin:  96% 786M/816M [00:03<00:00, 220MB/s]\u001b[A\n",
            "pytorch_model-00008-of-00008.bin: 100% 816M/816M [00:03<00:00, 238MB/s]\n",
            "Downloading shards: 100% 8/8 [01:28<00:00, 11.06s/it]\n",
            "Loading checkpoint shards:   0% 0/8 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Loading checkpoint shards: 100% 8/8 [01:00<00:00,  7.54s/it]\n",
            "generation_config.json: 100% 111/111 [00:00<00:00, 656kB/s]\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 14:12:30\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m277\u001b[0m - \u001b[1mUsing block size 1024\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 14:12:30\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m339\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:247: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
            "  warnings.warn(\n",
            "  0% 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.6708, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.1}\n",
            "  3% 1/30 [00:59<28:50, 59.68s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.6708, 'learning_rate': 0.00013333333333333334, 'epoch': 1.1}\n",
            "  7% 2/30 [02:04<29:15, 62.69s/it]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 1.6187, 'learning_rate': 0.0002, 'epoch': 2.1}\n",
            "{'train_runtime': 188.5499, 'train_samples_per_second': 1.862, 'train_steps_per_second': 0.159, 'train_loss': 1.6534137328465779, 'epoch': 2.1}\n",
            " 10% 3/30 [03:08<28:16, 62.85s/it]\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 14:15:40\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m477\u001b[0m - \u001b[1mFinished training, saving model...\u001b[0m\n",
            "\u001b[1m🚀 INFO  \u001b[0m | \u001b[32m2024-01-31 14:15:40\u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m510\u001b[0m - \u001b[1mPushing model to hub...\u001b[0m\n",
            "adapter_model.safetensors:   0% 0.00/27.3M [00:00<?, ?B/s]\n",
            "adapter_model.safetensors:   0% 0.00/27.3M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "optimizer.pt:   0% 0.00/54.6M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "scheduler.pt:   0% 0.00/1.06k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "rng_state.pth:   0% 0.00/14.2k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 9 LFS files:   0% 0/9 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "rng_state.pth: 100% 14.2k/14.2k [00:00<00:00, 58.2kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "scheduler.pt: 100% 1.06k/1.06k [00:00<00:00, 4.20kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:   0% 16.4k/54.6M [00:00<15:44, 57.8kB/s]\u001b[A\u001b[A\n",
            "scheduler.pt: 100% 1.06k/1.06k [00:00<00:00, 2.85kB/s]\n",
            "rng_state.pth: 100% 14.2k/14.2k [00:00<00:00, 35.6kB/s]\n",
            "\n",
            "\n",
            "optimizer.pt:   1% 541k/54.6M [00:00<00:32, 1.66MB/s] \u001b[A\u001b[A\n",
            "adapter_model.safetensors:   1% 197k/27.3M [00:00<00:54, 494kB/s]  \n",
            "\n",
            "optimizer.pt:  11% 5.83M/54.6M [00:00<00:02, 17.4MB/s]\u001b[A\u001b[A\n",
            "adapter_model.safetensors:  18% 4.95M/27.3M [00:00<00:01, 13.1MB/s]\u001b[A\n",
            "\n",
            "adapter_model.safetensors:   2% 541k/27.3M [00:00<00:23, 1.13MB/s]\n",
            "adapter_model.safetensors:  36% 9.86M/27.3M [00:00<00:00, 20.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "tokenizer.model:   0% 0.00/493k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "adapter_model.safetensors:  54% 14.6M/27.3M [00:00<00:00, 27.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "adapter_model.safetensors:   5% 1.31M/27.3M [00:00<00:12, 2.14MB/s]\n",
            "\n",
            "training_args.bin: 100% 4.73k/4.73k [00:00<00:00, 28.8kB/s]\n",
            "adapter_model.safetensors:   6% 1.70M/27.3M [00:01<00:11, 2.31MB/s]\n",
            "\n",
            "optimizer.pt:  43% 23.7M/54.6M [00:01<00:01, 30.5MB/s]\u001b[A\u001b[A\n",
            "adapter_model.safetensors:   8% 2.16M/27.3M [00:01<00:09, 2.59MB/s]\n",
            "\n",
            "optimizer.pt:  53% 28.8M/54.6M [00:01<00:00, 34.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.model:   0% 0.00/493k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 802kB/s]\n",
            "\n",
            "adapter_model.safetensors:  95% 26.0M/27.3M [00:01<00:00, 25.8MB/s]\u001b[A\n",
            "\n",
            "adapter_model.safetensors:  12% 3.19M/27.3M [00:01<00:07, 3.11MB/s]\n",
            "\n",
            "\n",
            "training_args.bin:   0% 0.00/4.73k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 1.33MB/s]\n",
            "adapter_model.safetensors: 100% 27.3M/27.3M [00:01<00:00, 16.5MB/s]\n",
            "\n",
            "\n",
            "training_args.bin: 100% 4.73k/4.73k [00:00<00:00, 32.5kB/s]\n",
            "adapter_model.safetensors:  20% 5.39M/27.3M [00:01<00:04, 4.46MB/s]\n",
            "\n",
            "optimizer.pt: 100% 54.6M/54.6M [00:02<00:00, 23.5MB/s]\n",
            "adapter_model.safetensors: 100% 27.3M/27.3M [00:04<00:00, 6.29MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 9 LFS files: 100% 9/9 [00:04<00:00,  1.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Completed 🎉\n",
        "After the command above is completed your Model will be uploaded to Hugging Face.\n",
        "\n",
        "#### Learn more about AutoTrain (optional)\n",
        "If you want to learn more about what command-line flags are available"
      ],
      "metadata": {
        "id": "gEf6G0iPc0Nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Inference Engine"
      ],
      "metadata": {
        "id": "FIoxuAEAfJ4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain llm -h"
      ],
      "metadata": {
        "id": "aYsYyXmrc0xu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "386aa0ef-70f5-4bbd-ed59-cedc5aa4add0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: autotrain <command> [<args>] llm [-h] [--text_column TEXT_COLUMN]\n",
            "                                        [--rejected_text_column REJECTED_TEXT_COLUMN]\n",
            "                                        [--prompt-text-column PROMPT_TEXT_COLUMN]\n",
            "                                        [--model-ref MODEL_REF] [--warmup_ratio WARMUP_RATIO]\n",
            "                                        [--optimizer OPTIMIZER] [--scheduler SCHEDULER]\n",
            "                                        [--weight_decay WEIGHT_DECAY]\n",
            "                                        [--max_grad_norm MAX_GRAD_NORM] [--add_eos_token]\n",
            "                                        [--block_size BLOCK_SIZE] [--peft] [--lora_r LORA_R]\n",
            "                                        [--lora_alpha LORA_ALPHA] [--lora_dropout LORA_DROPOUT]\n",
            "                                        [--logging_steps LOGGING_STEPS]\n",
            "                                        [--evaluation_strategy EVALUATION_STRATEGY]\n",
            "                                        [--save_total_limit SAVE_TOTAL_LIMIT]\n",
            "                                        [--save_strategy SAVE_STRATEGY] [--auto_find_batch_size]\n",
            "                                        [--mixed-precision MIXED_PRECISION]\n",
            "                                        [--quantization QUANTIZATION]\n",
            "                                        [--model_max_length MODEL_MAX_LENGTH] [--trainer TRAINER]\n",
            "                                        [--target_modules TARGET_MODULES] [--merge_adapter]\n",
            "                                        [--use_flash_attention_2] [--dpo-beta DPO_BETA]\n",
            "                                        [--apply_chat_template] [--padding PADDING] [--train]\n",
            "                                        [--deploy] [--inference] [--username USERNAME]\n",
            "                                        [--backend BACKEND] [--token TOKEN] [--repo-id REPO_ID]\n",
            "                                        [--push-to-hub] --model MODEL --project-name PROJECT_NAME\n",
            "                                        [--seed SEED] [--epochs EPOCHS]\n",
            "                                        [--gradient-accumulation GRADIENT_ACCUMULATION]\n",
            "                                        [--disable_gradient_checkpointing] [--lr LR] [--log LOG]\n",
            "                                        [--data-path DATA_PATH] [--train-split TRAIN_SPLIT]\n",
            "                                        [--valid-split VALID_SPLIT] [--batch-size BATCH_SIZE]\n",
            "\n",
            "✨ Run AutoTrain LLM\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --text_column TEXT_COLUMN, --text-column TEXT_COLUMN\n",
            "                        Text column to use\n",
            "  --rejected_text_column REJECTED_TEXT_COLUMN, --rejected-text-column REJECTED_TEXT_COLUMN\n",
            "                        Rejected text column to use\n",
            "  --prompt-text-column PROMPT_TEXT_COLUMN, --prompt-text-column PROMPT_TEXT_COLUMN\n",
            "                        Prompt text column to use\n",
            "  --model-ref MODEL_REF\n",
            "                        Reference model to use for DPO when not using PEFT\n",
            "  --warmup_ratio WARMUP_RATIO, --warmup-ratio WARMUP_RATIO\n",
            "                        Warmup proportion to use\n",
            "  --optimizer OPTIMIZER\n",
            "                        Optimizer to use\n",
            "  --scheduler SCHEDULER\n",
            "                        Scheduler to use\n",
            "  --weight_decay WEIGHT_DECAY, --weight-decay WEIGHT_DECAY\n",
            "                        Weight decay to use\n",
            "  --max_grad_norm MAX_GRAD_NORM, --max-grad-norm MAX_GRAD_NORM\n",
            "                        Max gradient norm to use\n",
            "  --add_eos_token, --add-eos-token\n",
            "                        Add EOS token to use\n",
            "  --block_size BLOCK_SIZE, --block-size BLOCK_SIZE\n",
            "                        Block size to use\n",
            "  --peft, --use-peft    Use PEFT\n",
            "  --lora_r LORA_R, --lora-r LORA_R\n",
            "                        Lora r to use\n",
            "  --lora_alpha LORA_ALPHA, --lora-alpha LORA_ALPHA\n",
            "                        Lora alpha to use\n",
            "  --lora_dropout LORA_DROPOUT, --lora-dropout LORA_DROPOUT\n",
            "                        Lora dropout to use\n",
            "  --logging_steps LOGGING_STEPS, --logging-steps LOGGING_STEPS\n",
            "                        Logging steps to use\n",
            "  --evaluation_strategy EVALUATION_STRATEGY, --evaluation-strategy EVALUATION_STRATEGY\n",
            "                        Evaluation strategy to use\n",
            "  --save_total_limit SAVE_TOTAL_LIMIT, --save-total-limit SAVE_TOTAL_LIMIT\n",
            "                        Save total limit to use\n",
            "  --save_strategy SAVE_STRATEGY, --save-strategy SAVE_STRATEGY\n",
            "                        Save strategy to use\n",
            "  --auto_find_batch_size, --auto-find-batch-size\n",
            "                        Auto find batch size True/False\n",
            "  --mixed-precision MIXED_PRECISION, --mixed-precision MIXED_PRECISION, --mp MIXED_PRECISION\n",
            "                        fp16, bf16, or None\n",
            "  --quantization QUANTIZATION, --quantization QUANTIZATION\n",
            "                        int4, int8, or None\n",
            "  --model_max_length MODEL_MAX_LENGTH, --max-len MODEL_MAX_LENGTH, --max-length MODEL_MAX_LENGTH\n",
            "                        Model max length to use\n",
            "  --trainer TRAINER     Trainer type to use\n",
            "  --target_modules TARGET_MODULES, --target-modules TARGET_MODULES\n",
            "                        Target modules to use\n",
            "  --merge_adapter, --merge-adapter\n",
            "                        Use this flag to merge PEFT adapter with the model\n",
            "  --use_flash_attention_2, --use-flash-attention-2, --use-fa2\n",
            "                        Use flash attention 2\n",
            "  --dpo-beta DPO_BETA, --dpo-beta DPO_BETA\n",
            "                        Beta for DPO trainer\n",
            "  --apply_chat_template, --apply-chat-template\n",
            "                        Apply chat template\n",
            "  --padding PADDING, --padding PADDING\n",
            "                        Padding side\n",
            "  --train               Train the model\n",
            "  --deploy              Deploy the model\n",
            "  --inference           Run inference\n",
            "  --username USERNAME   Hugging Face Hub Username\n",
            "  --backend BACKEND     Backend to use: default or spaces. Spaces backend requires push_to_hub and\n",
            "                        repo_id\n",
            "  --token TOKEN         Hub token\n",
            "  --repo-id REPO_ID     Hub repo id\n",
            "  --push-to-hub         Push to hub\n",
            "  --model MODEL         Model to use for training\n",
            "  --project-name PROJECT_NAME\n",
            "                        Output directory or repo id\n",
            "  --seed SEED           Seed\n",
            "  --epochs EPOCHS       Number of training epochs\n",
            "  --gradient-accumulation GRADIENT_ACCUMULATION\n",
            "                        Gradient accumulation steps\n",
            "  --disable_gradient_checkpointing, --disable-gradient-checkpointing, --disable-gc\n",
            "                        Disable gradient checkpointing\n",
            "  --lr LR               Learning rate\n",
            "  --log LOG             Use experiment tracking\n",
            "  --data-path DATA_PATH\n",
            "                        Train dataset to use\n",
            "  --train-split TRAIN_SPLIT\n",
            "                        Test dataset split to use\n",
            "  --valid-split VALID_SPLIT\n",
            "                        Validation dataset split to use\n",
            "  --batch-size BATCH_SIZE, --train-batch-size BATCH_SIZE\n",
            "                        Training batch size to use\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q peft  accelerate bitsandbytes safetensors"
      ],
      "metadata": {
        "id": "5m1ouhWhc2fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import transformers\n",
        "adapters_name = \"Swapnilg915/mistral-7b-mj-finetuned\"\n",
        "model_name = \"filipealmeida/Mistral-7B-Instruct-v0.1-sharded\" #\"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "\n",
        "device = \"cuda\" # the device to load the model onto"
      ],
      "metadata": {
        "id": "8s-nDnnPc--U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "id": "HosPywN_dEpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_4bit=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "090023f235604651a43896ac5451bc97",
            "4ebf9c48f7204d7f8eb77c8bd79c47b2",
            "d7d79d8004164838b16d0a1253292faa",
            "c78847b85bea407bac7a9469fda54bc4",
            "43584e2ea0234e78bbbd350321ea6f8b",
            "85e736eeff2141a482d819b3da31b9b1",
            "b214e45c1a034211b64acc31056944f0",
            "9354831ec0b441228e2457a77119765c",
            "4aee667c7ddf40c28121c39529d6b894",
            "bd0ed51f86fc401ba20833f164fd12a9",
            "63aa86e0b6704738aa18f1e62fa56bab"
          ]
        },
        "id": "GtZx4CZUdt1f",
        "outputId": "d3b29015-6d3d-4846-e848-66560fcc6ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "090023f235604651a43896ac5451bc97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Peft Model Loading with upload model"
      ],
      "metadata": {
        "id": "Uh5Xc0clfQkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PeftModel.from_pretrained(model, adapters_name)"
      ],
      "metadata": {
        "id": "Rt6sOPFVdvWX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "af58df3abe4c4727b4c8ebe4e2d02cee",
            "780cefa5afcb45ec9e34a26b66424084",
            "ed1d62af41174f57b749ddcf1a09af8f",
            "dd1dadf60c3d4b379f8cc3733f34c3e6",
            "4a2125c2cd054a62ab4258e9e810b94c",
            "82885845628244c380854f34a7da301e",
            "6860adc8501b46c09ddcfb409e0edc01",
            "78401abe8c3f4b5abbe295f48c18816e",
            "75b07bf4dfc84a549975630c4e964bb2",
            "ccfd8f4b69f94a2e85c9ab2dcc479841",
            "a12add763b5943bf82fdd7009549cd69",
            "cc025a8916c3473d8fd839abf99c60cd",
            "e77f7fce481a45e4b7b257910329f1fe",
            "ccdb8e0229514f97a9ca37589555836c",
            "836b45b8858c4cbabd230cb454b02c70",
            "e8c518a42393470d8fd7556c26576c69",
            "0bdeb36858f2495e9802f7b395e829bf",
            "122eaf73c05f415da8df456f7655faea",
            "1eaee89f775d462aae48858fb4670fb6",
            "5f040bc7c9384456854f4db6cbd17129",
            "2e8062d5592a4f7f9738d67f6208b938",
            "3d05d02b73b44096a60ebd9c4f84fb6c"
          ]
        },
        "outputId": "55e893e4-ca8e-42f7-df90-a89335a6d4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af58df3abe4c4727b4c8ebe4e2d02cee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/27.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc025a8916c3473d8fd839abf99c60cd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.bos_token_id = 1\n",
        "\n",
        "stop_token_ids = [0]\n",
        "\n",
        "print(f\"Successfully loaded the model {model_name} into memory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3OArVILeoZH",
        "outputId": "1554dcbf-aaae-45fd-e810-f0e34c0e00b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded the model filipealmeida/Mistral-7B-Instruct-v0.1-sharded into memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"[INST] generate a midjourney prompt for A person walks in the rain [/INST]\"\n",
        "\n",
        "encoded = tokenizer(text, return_tensors=\"pt\", add_special_tokens=False)\n",
        "model_input = encoded\n",
        "model.to(device)\n",
        "generated_ids = model.generate(**model_input, max_new_tokens=200, do_sample=True)\n",
        "decoded = tokenizer.batch_decode(generated_ids)\n",
        "print(decoded[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbOOX8cve0lR",
        "outputId": "6615d750-d853-4d28-c55f-26aee75f1325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1408: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST] generate a midjourney prompt for A person walks in the rain [/INST] As the rain continues to pour down, the protagonist reflects on their past mistakes and how they've led them to where they are now. They take a deep breath and try to make a conscious decision to turn their life around, but the weight of their past seems almost too much to bear. They could give up and accept their fate, or they could keep pushing forward and fight for a brighter future. What will they do?</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wPZmHPDF5Voh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}